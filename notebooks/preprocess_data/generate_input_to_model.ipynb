{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "generate_input_to_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v58gNg7K_RCf",
        "colab_type": "text"
      },
      "source": [
        "Specifying tensorflow version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlC29-r3_JwO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03HFN3Fa_Nqa",
        "colab_type": "text"
      },
      "source": [
        "Download concra project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jl6m02qsBD_2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/mrezende/concra.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bz4QJBsy2_Ib",
        "colab_type": "text"
      },
      "source": [
        "Go to StackOverflow-Question-Code-Dataset home"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQBj2mkn3HXl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/concra/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6STBQy-2z_A",
        "colab_type": "text"
      },
      "source": [
        "Get question ids and codes labeled\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLzEz8_NB03I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib\n",
        "import pickle\n",
        "import sys\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import json\n",
        "from gensim.models import Word2Vec\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "from data_processing.code_processing import *\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "\n",
        "iid_labeled = []\n",
        "with open('data/original/text/python_multi_code_iids.txt','r') as f:\n",
        "  lines = f.readlines()\n",
        "  for line in lines:\n",
        "    iid_labeled.append(line.rstrip())\n",
        "\n",
        "qid_to_title = json.load(open('data/original/json/python_how_to_do_it_by_classifier_multiple_qid_to_title.json','rb'))\n",
        "\n",
        "q_code_snippet = json.load(open('data/original/json/python_how_to_do_it_by_classifier_multiple_iid_to_code.json', 'rb'))\n",
        "\n",
        "all_agreed_iid = json.load(open('data/original/json/all_agreed_iid_to_label.json', 'rb'))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvJOfnfCm3Yv",
        "colab_type": "text"
      },
      "source": [
        "Total of code snippets marked as correct"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpbJY45kjVOy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d15431f5-4a82-4b48-f4f7-28fccb7e2ca1"
      },
      "source": [
        "iid_marked_as_correct = [key for key, label in all_agreed_iid.items() if label == 1]\n",
        "len(iid_marked_as_correct)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2169"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDpFfpWTetxc",
        "colab_type": "text"
      },
      "source": [
        "Calling a function **tokenize_code_corpus**:\n",
        "\n",
        "Tokenizing a code snippet into a list of tokens.\n",
        "  Numbers/strings are replaced with NUMBER/STRING.\n",
        "  Comments are removed. \n",
        "\n",
        "  (modified: replacing variable names with VAR)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flTRgCRifF1u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ad0b2b40-25d1-4404-9bbb-23c3ebda1a06"
      },
      "source": [
        "qid_code_labeled = dict([(key, q_code_snippet[key]) for key in iid_labeled])\n",
        "\n",
        "tokenized_code, bool_failed_var, bool_failed_token = tokenize_code_corpus(qid_code_labeled, \"python\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Failed line: \n",
            "Failed code line: 6  12.34  0.34  b\n",
            "failed tokenization qid: (36874246, 1)\n",
            "Failed line: \n",
            "Failed code line: (#+[^\\\\\\n]*)\n",
            "failed tokenization qid: (24829843, 0)\n",
            "Failed line: \n",
            "Failed code line:                       1    2    3\n",
            "Failed line: \n",
            "Failed code line:   4    5    6    7    8    9   10\n",
            "failed tokenization qid: (19366213, 0)\n",
            "Failed line: \n",
            "Failed code line: abcQdefN\n",
            "failed tokenization qid: (28617825, 1)\n",
            "Failed line: \n",
            "Failed code line:       ...\n",
            "Failed line: \n",
            "Failed code line: \n",
            "Failed line: \n",
            "Failed code line:       ...\n",
            "failed tokenization qid: (28127191, 1)\n",
            "Failed line: \n",
            "Failed code line: response = cli.start(container=container.get('Id'),links=(('EXISTING_CONTAINER', 'LINK_NAME'))\n",
            "failed tokenization qid: (37144357, 5)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (13696556, 0)\n",
            "Failed line: \n",
            "Failed code line:         print('{:>{w}s}'.format(value, w=len(head)), end=' ')\n",
            "failed tokenization qid: (34115047, 4)\n",
            "Failed line: \n",
            "Failed code line:     destination.write(line.strip() + \",a\\n\"))\n",
            "failed tokenization qid: (15484494, 0)\n",
            "Failed line: \n",
            "Failed code line: -> {X1, L1, X2, L2, X3, L3, X4, A1, X5, A2}\n",
            "failed tokenization qid: (5455693, 4)\n",
            "Failed line: \n",
            "Failed code line:     print '\\n===\\n'.join(results)\n",
            "failed tokenization qid: (24435625, 3)\n",
            "Failed line: \n",
            "Failed code line:     setattr(self, event_name, Event(self.__class__.__name__ + '.' + event_name)\n",
            "failed tokenization qid: (30916577, 1)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (4291843, 4)\n",
            "Failed line: \n",
            "Failed code line:               setattr(self,k,v)\n",
            "failed tokenization qid: (31325860, 0)\n",
            "Failed line: \n",
            "Failed code line: [(0, 1), (2, 3), (4, 5), (6, 7)]\n",
            "failed tokenization qid: (6007736, 1)\n",
            "Failed line: \n",
            "Failed code line:              extract(data, writer)\n",
            "failed tokenization qid: (32994840, 2)\n",
            "1000\n",
            "Failed line: \n",
            "Failed code line: (?<={).*?(?=:)\n",
            "failed tokenization qid: (33053882, 0)\n",
            "Failed line: \n",
            "Failed code line:    d[2], a[5], c[3], a[6], c[4]}\n",
            "failed tokenization qid: (5455693, 5)\n",
            "Failed line: \n",
            "Failed code line:  )\n",
            "failed tokenization qid: (21490597, 2)\n",
            "Failed line: \n",
            "Failed code line:  ]\n",
            "failed tokenization qid: (1911281, 0)\n",
            "Failed line: \n",
            "Failed code line:            d[key] = value\n",
            "failed tokenization qid: (28818881, 1)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (30410821, 2)\n",
            "Failed line: \n",
            "Failed code line: print selectFunction(userInputOption)\n",
            "failed tokenization qid: (34044709, 1)\n",
            "Failed line: \n",
            "Failed code line: arrays = [np.array((array.float(i) for i in r)) for r in csv.reader(open(your_file), delimiter=' '))]\n",
            "failed tokenization qid: (6213336, 3)\n",
            "Failed line: \n",
            "Failed code line:     print sorted(data, key=sort_key))\n",
            "failed tokenization qid: (26953517, 1)\n",
            "2000\n",
            "Failed line: \n",
            "Failed code line: print(\"Value %i = %s\" % (index, self.box[key].get())\n",
            "failed tokenization qid: (11446652, 0)\n",
            "Failed line: \n",
            "Failed code line: STR\\(\"((?:\\\\\"|[^\"])*)\"\\)\n",
            "failed tokenization qid: (27887545, 2)\n",
            "Failed line: \n",
            "Failed code line: np.recfromcsv(datafile,delimiter='\\t'))\n",
            "failed tokenization qid: (23056069, 3)\n",
            "Failed line: \n",
            "Failed code line:     A  B\n",
            "failed tokenization qid: (23718154, 1)\n",
            "Failed line: \n",
            "Failed code line: print V(theta,N)\n",
            "failed tokenization qid: (12167660, 1)\n",
            "Failed line: \n",
            "Failed code line:          self.user = wx.TextCtrl(self,-1)\n",
            "failed tokenization qid: (26636519, 0)\n",
            "Failed line: \n",
            "Failed code line:     outref.close()\n",
            "failed tokenization qid: (21542700, 0)\n",
            "Failed line: \n",
            "Failed code line: second_output = random_y[np.in1d(random_y,y)\n",
            "failed tokenization qid: (37144574, 0)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (35992088, 2)\n",
            "Failed line: \n",
            "Failed code line: print(by_price[:3)\n",
            "failed tokenization qid: (35809428, 11)\n",
            "Failed line: \n",
            "Failed code line:     print 'not Found'\n",
            "Failed line: \n",
            "Failed code line:     print 'not Found'\n",
            "failed tokenization qid: (13052695, 2)\n",
            "Failed line: \n",
            "Failed code line: open('out', 'w').write('yes\\n'.join(','.join(line.split() for line in open('myfile', 'r').read().split('\\n')))\n",
            "failed tokenization qid: (22649844, 1)\n",
            "Failed line: \n",
            "Failed code line: expr.xreplace(Transform(split, lambda i: isinstance(i, Integral))\n",
            "failed tokenization qid: (18434892, 1)\n",
            "Failed line: \n",
            "Failed code line:     return df\n",
            "failed tokenization qid: (21954197, 0)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (18108469, 0)\n",
            "Failed line: \n",
            "Failed code line: Character C has 1 occurrences so far\n",
            "failed tokenization qid: (29921051, 0)\n",
            "Failed line: \n",
            "Failed code line: //*[contains(text(),'name']/parent::*/following-sibling::*[1]/*[@class='name']/text()\n",
            "failed tokenization qid: (9217636, 0)\n",
            "3000\n",
            "Failed line: \n",
            "Failed code line:         stem_lookup.setdefault(synonym, []).append(stem)) #make a new list if this synonym not used yet\n",
            "failed tokenization qid: (9073038, 2)\n",
            "Failed line: \n",
            "Failed code line: print(\"Hello, your name is {name}, you are {age} years old and you live in {city}\".format(name=name, age=age, city=city)\n",
            "failed tokenization qid: (36906268, 0)\n",
            "Failed line: \n",
            "Failed code line:     F[tup]=tup\n",
            "Failed line: \n",
            "Failed code line:          [ 1.,  2.,  2.]]]])\n",
            "failed tokenization qid: (29466015, 0)\n",
            "Failed line: \n",
            "Failed code line: out_file.write('%s\\t%s\\n' % (str(i), str(j))\n",
            "failed tokenization qid: (8454543, 1)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (37028384, 0)\n",
            "Failed line: \n",
            "Failed code line: ]\n",
            "failed tokenization qid: (21676487, 2)\n",
            "Failed line: \n",
            "Failed code line: def\\s+(?=[a-z]+(?:[A-Z][a-z0-9]+)*\\s*\\().*?\\(\n",
            "failed tokenization qid: (6512027, 0)\n",
            "Failed line: \n",
            "Failed code line:     print(i, j)\n",
            "failed tokenization qid: (25876610, 0)\n",
            "Failed line: \n",
            "Failed code line: print(items)\n",
            "failed tokenization qid: (17956684, 0)\n",
            "Failed line: \n",
            "Failed code line: print(min_indices)\n",
            "failed tokenization qid: (32493055, 0)\n",
            "Failed line: \n",
            "Failed code line:     f.readline().count(\"\\t\")\n",
            "Failed line: \n",
            "Failed code line:     num_columns = len(fin.readline().split('\\t'))\n",
            "failed tokenization qid: (29922108, 3)\n",
            "Failed line: \n",
            "Failed code line: In [21]: frame.apply(lambda x: 2 * x['b'] if x['a'] else x['b'], axis=1\n",
            "failed tokenization qid: (17966315, 1)\n",
            "Failed line: \n",
            "Failed code line: df.resample(\"1w\"), how={'A': np.sum})\n",
            "failed tokenization qid: (27905269, 0)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (20449506, 0)\n",
            "Failed line: \n",
            "Failed code line:         prints.append(block.speed_x) #temp print\n",
            "failed tokenization qid: (24774085, 0)\n",
            "4000\n",
            "Failed line: \n",
            "Failed code line: np.sum(sm - z, axis=0)  # let numpy broadcast sm\n",
            "failed tokenization qid: (22184107, 3)\n",
            "Failed line: \n",
            "Failed code line:         masterIndex[key]= partialIndex[key]\n",
            "failed tokenization qid: (21105803, 0)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (25380847, 1)\n",
            "Failed line: \n",
            "Failed code line:             print(\"{} - {}\".format(change[0], change[1])\n",
            "failed tokenization qid: (28095647, 0)\n",
            "Failed line: \n",
            "Failed code line: (5809, 'XYZ')\n",
            "failed tokenization qid: (34572902, 1)\n",
            "Failed line: \n",
            "Failed code line:         print \"line{0} = {1}\".format(i,x)\n",
            "failed tokenization qid: (13428318, 0)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (36998069, 0)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (28960274, 1)\n",
            "Failed line: \n",
            "Failed code line: age_range, freq = zip(*sorted(age_freq.items(), key=lambda x: (int(x[3].split('-')[0]) + int(x[3].split('-')[1]) / 2))\n",
            "failed tokenization qid: (35903366, 1)\n",
            "Failed line: \n",
            "Failed code line: format_spec ::=  [[fill]align][sign][#][0][width][,][.precision][type]\n",
            "failed tokenization qid: (18937508, 0)\n",
            "5000\n",
            "Failed line: \n",
            "Failed code line:      open('path/to/output.csv', 'wb') as outf:\n",
            "Failed line: \n",
            "Failed code line:                          })\n",
            "failed tokenization qid: (33225630, 0)\n",
            "Failed line: \n",
            "Failed code line:     tags.extend([e.strip(\"'():,&;+?][ \") for e in item if e not in remove]\n",
            "failed tokenization qid: (27011647, 2)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (17091446, 0)\n",
            "Failed line: \n",
            "Failed code line:     return long(gmpy2.powmod(base, power modulus)\n",
            "failed tokenization qid: (28523602, 1)\n",
            "Failed line: \n",
            "Failed code line:     adict[(i,i)]=1\n",
            "failed tokenization qid: (32408355, 0)\n",
            "Failed line: \n",
            "Failed code line: data['new_col'] = data['acend'].rolling(window=20).sum().div(data['Volume'].rolling(window=20).sum().subtract(data['acend'].rolling(window=20).sum()).mul(100).fillna(0)\n",
            "failed tokenization qid: (37523730, 1)\n",
            "Failed line: \n",
            "Failed code line: print sess.run(y_) # ==> \"array([2, 6], dtype=int32)\"\n",
            "failed tokenization qid: (34987509, 1)\n",
            "Failed line: \n",
            "Failed code line: /(https?:[;\\/?\\\\@&=+$,\\[\\]A-Za-z0-9\\-_\\.\\!\\~\\*\\'\\(\\)%][\\;\\/\\?\\:\\@\\&\\=\\+\\$\\,\\[\\]A-Za-z0-9\\-_\\.\\!\\~\\*\\'\\(\\)%#]*|[KZ]:\\\\*.*\\w+)/g\n",
            "failed tokenization qid: (1727535, 0)\n",
            "Failed line: \n",
            "Failed code line:         print(\"Yes!\")\n",
            "failed tokenization qid: (30008937, 2)\n",
            "Failed line: \n",
            "Failed code line:         print(\"All the user options, and handle input and routing here\")\n",
            "failed tokenization qid: (22572393, 1)\n",
            "6000\n",
            "Failed line: \n",
            "Failed code line: result = [''.join(sublist) for sublist in initial]\n",
            "failed tokenization qid: (17379035, 1)\n",
            "Failed line: \n",
            "Failed code line: array([2, 3]])\n",
            "failed tokenization qid: (18561478, 0)\n",
            "Failed line: \n",
            "Failed code line:     sys.exit(1)\n",
            "failed tokenization qid: (12828771, 1)\n",
            "Failed line: \n",
            "Failed code line: application = webapp2.WSGIApplication([('/', MainHandler)], debug=False)\n",
            "failed tokenization qid: (25784547, 0)\n",
            "Failed line: \n",
            "Failed code line:         os.unlink(tmp.name)\n",
            "failed tokenization qid: (34189294, 2)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (5133262, 0)\n",
            "Failed line: \n",
            "Failed code line: //h3[@class='r']/a[not(contains(@href,'google')) and not(contains(@href,'facebook')) and not(contains(@href,'twitter'))]/@href\")\n",
            "failed tokenization qid: (28163626, 0)\n",
            "Failed line: \n",
            "Failed code line:   n\n",
            "failed tokenization qid: (24087260, 0)\n",
            "Failed line: \n",
            "Failed code line:            return f(args)\n",
            "failed tokenization qid: (3929317, 1)\n",
            "Failed line: \n",
            "Failed code line:           stats.append(t)\n",
            "failed tokenization qid: (28447487, 0)\n",
            "Failed line: \n",
            "Failed code line: qs = Category.objects.filter(reduce(operator.and_, (Q(title__values=x) for x in value_list))\n",
            "failed tokenization qid: (27219000, 0)\n",
            "Failed line: \n",
            "Failed code line:     print(\"   > {}: \\033[1m\\033[32m{:d} visit\\033[0m'.format(key, value))\n",
            "failed tokenization qid: (27185592, 1)\n",
            "Failed line: \n",
            "Failed code line: dtype: object\n",
            "failed tokenization qid: (17748913, 0)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (17232651, 0)\n",
            "7000\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (21296211, 3)\n",
            "Failed line: \n",
            "Failed code line:                       auto_delete=False)\n",
            "failed tokenization qid: (16691161, 0)\n",
            "Failed line: \n",
            "Failed code line:             out.append(v)\n",
            "failed tokenization qid: (31415592, 3)\n",
            "Failed line: \n",
            "Failed code line: //tr[contains(.,'%s')]\" % tr_data and //span[contains(.,'%s')]\" % span_data)\n",
            "failed tokenization qid: (36156538, 0)\n",
            "Failed line: \n",
            "Failed code line:             pcode.append(pc)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (17614852, 0)\n",
            "Failed line: \n",
            "Failed code line:     return astr.decode('utf-8')\n",
            "Failed line: \n",
            "Failed code line:             return super(MyFormatter, self).convert_field(value, conversion)\n",
            "failed tokenization qid: (32207420, 1)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (7182469, 2)\n",
            "Failed line: \n",
            "Failed code line:         cleaned_tag = element.tag.replace('{'+element.nsmap[element.prefix]+'}','')      \n",
            "failed tokenization qid: (33959772, 1)\n",
            "Failed line: \n",
            "Failed code line: affich((('params1', [1, 2]), ('params2', []), ('params3', [3, 4, 5, 6]), ('params5', [7, 8]))\n",
            "failed tokenization qid: (26590213, 0)\n",
            "Failed line: \n",
            "Failed code line:     return [''.join([func(w[x]) if x == char else w[x] for x in xrange(len(w))]) for w in l]\n",
            "failed tokenization qid: (13734840, 0)\n",
            "Failed line: \n",
            "Failed code line:     print id\n",
            "failed tokenization qid: (24809125, 2)\n",
            "Failed line: \n",
            "Failed code line:     user.right_question_count = users_with_right_questions[user.id]\n",
            "failed tokenization qid: (31112835, 1)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (7205826, 0)\n",
            "8000\n",
            "Failed line: \n",
            "Failed code line:     new.append(i + ' ' + str(f.count(i)) # Note that i is a string, so str() is unnecessary\n",
            "failed tokenization qid: (18568309, 1)\n",
            "Failed line: \n",
            "Failed code line:             element.text = str(text)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (8666972, 0)\n",
            "Failed line: \n",
            "Failed code line: somelist = [item for item in somelist if item]\n",
            "failed tokenization qid: (26066058, 1)\n",
            "Failed line: \n",
            "Failed code line:     print('x.{} = {!r}'.format(attrname, getattr(x, attrname))\n",
            "failed tokenization qid: (19123707, 2)\n",
            "Failed line: \n",
            "Failed code line:     print i + len(myList)\n",
            "failed tokenization qid: (13381213, 1)\n",
            "Failed line: \n",
            "Failed code line:    ....:     \n",
            "failed tokenization qid: (34861234, 0)\n",
            "Failed line: \n",
            "Failed code line:  print c.fetchall()\n",
            "failed tokenization qid: (12207828, 0)\n",
            "Failed line: \n",
            "Failed code line:     return new_sentence\n",
            "failed tokenization qid: (22434092, 0)\n",
            "Failed line: \n",
            "Failed code line: ('x1+dx', 'y1+dy+dy')\n",
            "failed tokenization qid: (10050554, 0)\n",
            "Failed line: \n",
            "Failed code line: this_button.configure(command=functools.partial(do_something, this_button)\n",
            "failed tokenization qid: (12694058, 1)\n",
            "Failed line: \n",
            "Failed code line:         print(str((position)) + ' is the value of k.')\n",
            "failed tokenization qid: (31887732, 0)\n",
            "Failed line: \n",
            "Failed code line:        'WaferEC': '\"140517\"'}}\n",
            "failed tokenization qid: (32960303, 1)\n",
            "Failed line: \n",
            "Failed code line:  u'New_York': (u'New_York', u'NY', datetime.datetime(2014, 8, 13, 0, 0), 10)}\n",
            "failed tokenization qid: (25288927, 2)\n",
            "Failed line: \n",
            "Failed code line: mydict = dict(zip(res[::2],[eval(x) for x in res[1::2]])\n",
            "failed tokenization qid: (18210319, 0)\n",
            "Failed line: \n",
            "Failed code line:               8 COMPARE_OP               0 (<)\n",
            "Failed line: \n",
            "Failed code line:              20 RETURN_VALUE\n",
            "Failed line: \n",
            "Failed code line:               9 JUMP_IF_FALSE_OR_POP    21\n",
            "Failed line: \n",
            "Failed code line:              18 COMPARE_OP               0 (<)\n",
            "failed tokenization qid: (12658197, 0)\n",
            "Failed line: \n",
            "Failed code line: soup.find_all('img', attrs={'id': pat}\n",
            "failed tokenization qid: (26849765, 1)\n",
            "9000\n",
            "Failed line: \n",
            "Failed code line:               9 LOAD_NAME                1 (x)\n",
            "Failed line: \n",
            "Failed code line:               9 CALL_FUNCTION            1 (1 positional, 0 keyword pair)\n",
            "failed tokenization qid: (37365311, 0)\n",
            "Failed line: \n",
            "Failed code line: df.groupby(df['date'].map(lambda x: x.hour)\n",
            "failed tokenization qid: (35139758, 0)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (37155335, 2)\n",
            "Failed line: \n",
            "Failed code line:         next()\n",
            "failed tokenization qid: (12848441, 0)\n",
            "Failed line: \n",
            "Failed code line:         m[i,j] = i*j\n",
            "failed tokenization qid: (35109888, 2)\n",
            "Failed line: \n",
            "Failed code line:     # use r\n",
            "failed tokenization qid: (15865750, 1)\n",
            "Failed line: \n",
            "Failed code line: # will give you a dataframe with the required values\n",
            "failed tokenization qid: (25139255, 1)\n",
            "Failed line: \n",
            "Failed code line:         x[\"b_list\"].eq_join(lambda x: x, r.table(\"B\"))[\"right\"]})\n",
            "failed tokenization qid: (20458617, 0)\n",
            "Failed line: \n",
            "Failed code line:         print(yaml.dump(data, Dumper=yaml.RoundTripDumper))\n",
            "failed tokenization qid: (32493647, 0)\n",
            "Failed line: \n",
            "Failed code line: Out[175]: Namespace(m=[['one', 'two']])\n",
            "failed tokenization qid: (29922885, 1)\n",
            "Failed line: \n",
            "Failed code line:     self.type = OptionMenu(..., command=lambda new_value, variable=var: self.VarMenu(new_value, variable)\n",
            "failed tokenization qid: (11428951, 1)\n",
            "Failed line: \n",
            "Failed code line: arrays = [np.array((array.float(i) for i in l.split())) for l in open(your_file))]\n",
            "failed tokenization qid: (6213336, 4)\n",
            "Failed line: \n",
            "Failed code line: mat = np.vstack([signal.split(\",\") for signal in f)])\n",
            "failed tokenization qid: (36170104, 0)\n",
            "Failed line: \n",
            "Failed code line:                 for name in nt_lol[0][0]._fields)\n",
            "failed tokenization qid: (6989193, 0)\n",
            "Failed line: \n",
            "Failed code line:      print '%s percent index: %s' % (i, perc(i, len(comb))\n",
            "failed tokenization qid: (29459779, 3)\n",
            "Failed line: \n",
            "Failed code line:         return '{} occurrences on {} pages'.format(self.occurrences, self.pages)\n",
            "failed tokenization qid: (15933516, 0)\n",
            "Failed line: \n",
            "Failed code line:             A                   B         D\n",
            "failed tokenization qid: (14529838, 2)\n",
            "10000\n",
            "Failed line: \n",
            "Failed code line:     outref.close()\n",
            "failed tokenization qid: (21542700, 1)\n",
            "Failed line: \n",
            "Failed code line:                                 ||\n",
            "failed tokenization qid: (37306395, 0)\n",
            "Failed line: \n",
            "Failed code line: fileName = splitFilePath [1]\n",
            "failed tokenization qid: (31440117, 0)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (33936017, 1)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "Failed line: \n",
            "Failed code line:            )\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (24666570, 1)\n",
            "Failed line: \n",
            "Failed code line:     pass  # here you might use this list of (k, v) tuples\n",
            "failed tokenization qid: (37643520, 3)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "Failed line: \n",
            "Failed code line:   /* \"_tmp.pyx\":9\n",
            "failed tokenization qid: (15317851, 1)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (32727964, 1)\n",
            "Failed line: \n",
            "Failed code line:      # replace the original file\n",
            "failed tokenization qid: (30411975, 0)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (35699226, 0)\n",
            "Failed line: \n",
            "Failed code line: \\*\\s*\\({2}[^)]*(?:\\)(?!\\))[^)]*)*\\){2}\\s*\n",
            "failed tokenization qid: (36924820, 1)\n",
            "Failed line: \n",
            "Failed code line:               9 STORE_ATTR               2 (c)\n",
            "failed tokenization qid: (10438990, 1)\n",
            "Failed line: \n",
            "Failed code line: result = operators[action](Alice, Bob)\n",
            "failed tokenization qid: (27029717, 0)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (21408606, 1)\n",
            "Failed line: \n",
            "Failed code line: itertools.starmap(vid, itertools.product([0,1,2,3], repeat = 3)))\n",
            "failed tokenization qid: (25045320, 0)\n",
            "Failed line: \n",
            "Failed code line:   \"']/Val[@name='account_number'],'- ','')\"\n",
            "failed tokenization qid: (7313394, 1)\n",
            "Failed line: \n",
            "Failed code line: cmds = '''\n",
            "Failed position: 5\n",
            "wordpunct_tokenizer tokenization: \n",
            "['=', \"'''\"]\n",
            "failed tokenization qid: (1615379, 0)\n",
            "Failed line: \n",
            "Failed code line:             return\n",
            "failed tokenization qid: (3291120, 1)\n",
            "Failed line: \n",
            "Failed code line: A_sorted, B_sorted = zip(*sorted(zip(A, B))\n",
            "failed tokenization qid: (19885637, 0)\n",
            "11000\n",
            "Failed line: \n",
            "Failed code line:      pd.concat([df3, df4], axis=1)].to_csv(f, header=False)\n",
            "failed tokenization qid: (30829748, 1)\n",
            "Failed line: \n",
            "Failed code line: 3 E1 to D1, E1 to F2\n",
            "failed tokenization qid: (32754295, 1)\n",
            "Failed line: \n",
            "Failed code line: print(list(removal(list_with_files, remove_list))\n",
            "failed tokenization qid: (36186703, 0)\n",
            "Failed line: \n",
            "Failed code line: (\\w+)=((?:\"(?:\\\\.|[^\\\\\"])*\"|'(?:\\\\.|[^\\\\'])*'|[^\\\\,\"'])+)\n",
            "failed tokenization qid: (2797644, 2)\n",
            "Failed line: \n",
            "Failed code line: filehandle.close()\n",
            "failed tokenization qid: (26856026, 0)\n",
            "Failed line: \n",
            "Failed code line:             chunksize += 1\n",
            "failed tokenization qid: (37221268, 2)\n",
            "Failed line: \n",
            "Failed code line: Ten - WR\n",
            "failed tokenization qid: (28115580, 0)\n",
            "Failed line: \n",
            "Failed code line:             # print >> fout, k[0], v, k[1]\n",
            "failed tokenization qid: (24475661, 1)\n",
            "Failed line: \n",
            "Failed code line:     return \"\".join(unique_justseen(text)\n",
            "failed tokenization qid: (37092752, 2)\n",
            "Failed line: \n",
            "Failed code line:  outref.close()\n",
            "failed tokenization qid: (14573182, 3)\n",
            "Failed line: \n",
            "Failed code line: 2\n",
            "failed tokenization qid: (32757073, 0)\n",
            "12000\n",
            "Failed line: \n",
            "Failed code line:         print \"line {0} = {1}\".format(i,line.split())\n",
            "failed tokenization qid: (13428318, 1)\n",
            "Failed line: \n",
            "Failed code line:         print(''.join('T' for o in range(i)))\n",
            "failed tokenization qid: (19439852, 0)\n",
            "Failed line: \n",
            "Failed code line:         number = efficientalgo(number)\n",
            "failed tokenization qid: (37758507, 0)\n",
            "Failed line: \n",
            "Failed code line:     variant.write(\"%s\\n\" % (\" \".join(number))\n",
            "failed tokenization qid: (31660477, 0)\n",
            "Failed line: \n",
            "Failed code line: print(\"\\n\".join(str(n,x))\n",
            "failed tokenization qid: (20175263, 0)\n",
            "Failed line: \n",
            "Failed code line: 2  [a]  NaN\n",
            "failed tokenization qid: (36017405, 3)\n",
            "Failed line: \n",
            "Failed code line: KeyError: ('bar', 'bar', 'foo')\n",
            "failed tokenization qid: (24527961, 2)\n",
            "Failed line: \n",
            "Failed code line: ...\n",
            "failed tokenization qid: (192109, 2)\n",
            "Failed line: \n",
            "Failed code line:     main(sys.argv[1])\n",
            "failed tokenization qid: (27003609, 1)\n",
            "Failed line: \n",
            "Failed code line:     default = len(arg1)\n",
            "failed tokenization qid: (24876826, 0)\n",
            "Failed line: \n",
            "Failed code line: OrderedDict(sorted(a_dict.items(), key=lambda item: item[1][1])    # Python 3\n",
            "failed tokenization qid: (11932729, 1)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (36571774, 0)\n",
            "Failed line: \n",
            "Failed code line:       dtype='<U14')\n",
            "failed tokenization qid: (34955618, 4)\n",
            "Failed line: \n",
            "Failed code line:         return words[0]\n",
            "failed tokenization qid: (4482050, 5)\n",
            "Failed line: \n",
            "Failed code line: # 10 loops, best of 3: 43.6 ms per loop\n",
            "failed tokenization qid: (35877661, 1)\n",
            "Failed line: \n",
            "Failed code line:     A[i]=np.c_[l,newC]\n",
            "failed tokenization qid: (33870862, 0)\n",
            "13000\n",
            "Failed line: \n",
            "Failed code line:     print i[1].strip()  #this removes the \\n\n",
            "failed tokenization qid: (37514272, 0)\n",
            "Failed line: \n",
            "Failed code line: print(map(str,tup2))== map(str,tup1)) # tuple(map.. python 3\n",
            "failed tokenization qid: (28986598, 0)\n",
            "Failed line: \n",
            "Failed code line: gnuplotcmds.append('set yrange[{0}:{1}]'.format(miny, maxy)\n",
            "failed tokenization qid: (27039116, 0)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (11836964, 1)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (26535503, 1)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (28665506, 0)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (22455511, 1)\n",
            "Failed line: \n",
            "Failed code line:     print next(val) # or do something appropriate\n",
            "failed tokenization qid: (11124545, 0)\n",
            "Failed line: \n",
            "Failed code line:     return func_to_call())\n",
            "failed tokenization qid: (36191146, 0)\n",
            "Failed line: \n",
            "Failed code line: u'Former Ford Motor Co. CEO joins Google board'\n",
            "failed tokenization qid: (25262556, 2)\n",
            "Failed line: \n",
            "Failed code line:     len(objects), file.name)\n",
            "failed tokenization qid: (28501135, 0)\n",
            "Failed line: \n",
            "Failed code line: ValueError: Cannot convert nan to Fraction.\n",
            "failed tokenization qid: (19374254, 2)\n",
            "Failed line: \n",
            "Failed code line: { print }\n",
            "failed tokenization qid: (27338752, 2)\n",
            "Failed line: \n",
            "Failed code line: result = list(chain.from_iterable(seq[i:i+step] for i in range(0, len(seq), step2))\n",
            "failed tokenization qid: (27268448, 0)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (9539702, 4)\n",
            "Failed line: \n",
            "Failed code line: array([2, 3]])\n",
            "failed tokenization qid: (18561478, 1)\n",
            "Failed line: \n",
            "Failed code line:     print \"you have made an invalid choice, try again.\"\n",
            "failed tokenization qid: (12828771, 0)\n",
            "Failed line: \n",
            "Failed code line:     print([td.text for td in row.xpath(\".//td[@class='dddefault'][text()])\n",
            "failed tokenization qid: (37090653, 0)\n",
            "14000\n",
            "Failed line: \n",
            "Failed code line: data.sort(key=lambda s:(s.identity,s.time))\n",
            "failed tokenization qid: (10972925, 2)\n",
            "Failed line: \n",
            "Failed code line:         else: i+=1\n",
            "failed tokenization qid: (34731948, 0)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (30603485, 1)\n",
            "Failed line: \n",
            "Failed code line: myList = list(BeautifulSoup(myString).strings))\n",
            "failed tokenization qid: (18763370, 0)\n",
            "Failed line: \n",
            "Failed code line:         second = 0\n",
            "failed tokenization qid: (33379486, 1)\n",
            "Failed line: \n",
            "Failed code line:        )\n",
            "failed tokenization qid: (9469182, 0)\n",
            "Failed line: \n",
            "Failed code line: test_lines = \"\"\"\n",
            "Failed position: 11\n",
            "wordpunct_tokenizer tokenization: \n",
            "['=', '\"\"\"']\n",
            "failed tokenization qid: (37424245, 0)\n",
            "Failed line: \n",
            "Failed code line:    ....:     \n",
            "failed tokenization qid: (9134964, 1)\n",
            "Failed line: \n",
            "Failed code line: 3\n",
            "failed tokenization qid: (13923091, 1)\n",
            "Failed line: \n",
            "Failed code line:   #The way we interact has changed, now we need to define a job queue\n",
            "failed tokenization qid: (20021051, 1)\n",
            "Failed line: \n",
            "Failed code line: []\n",
            "failed tokenization qid: (5241391, 2)\n",
            "Failed line: \n",
            "Failed code line: ...    return sum((x-y)**2 for x,y in zip(tup,tup[1:]+(tup[0],))))\n",
            "failed tokenization qid: (32104514, 3)\n",
            "Failed line: \n",
            "Failed code line:         del data[k]\n",
            "failed tokenization qid: (35165864, 0)\n",
            "Failed line: \n",
            "Failed code line:     if x[0][1]==3: d[x[0][0]].append(list(x[1])[0])\n",
            "failed tokenization qid: (26132819, 2)\n",
            "Failed line: \n",
            "Failed code line: ...\n",
            "failed tokenization qid: (31212893, 0)\n",
            "15000\n",
            "Failed line: \n",
            "Failed code line:  b- five\n",
            "failed tokenization qid: (15932916, 2)\n",
            "Failed line: \n",
            "Failed code line: return new_list\n",
            "failed tokenization qid: (4957030, 0)\n",
            "Failed line: \n",
            "Failed code line: [u'java', u'.', u'lang', u'.', u'String'], {})\n",
            "failed tokenization qid: (14420156, 2)\n",
            "Failed line: \n",
            "Failed code line: binomial(n, r)\n",
            "failed tokenization qid: (37082346, 0)\n",
            "Failed line: \n",
            "Failed code line: ,?\\s*([^',]*(?:'[^']*'[^',]*)*)\n",
            "failed tokenization qid: (33414028, 0)\n",
            "Failed line: \n",
            "Failed code line:    ctypes.windll.kernel32.WriteConsoleW (gHandle, c_wchar_p (string), c_ulong(len (string)), c_void_p (), None)\n",
            "failed tokenization qid: (27612545, 1)\n",
            "Failed line: \n",
            "Failed code line:        return orig_getenv(key, default).value\n",
            "failed tokenization qid: (21250645, 1)\n",
            "Failed line: \n",
            "Failed code line:                 item['matches'].append(matchDict)\n",
            "failed tokenization qid: (35681392, 2)\n",
            "16000\n",
            "Failed line: \n",
            "Failed code line:          self.Bind(wx.EVT_KILL_FOCUS,self.OnKillFocus)\n",
            "failed tokenization qid: (34379079, 1)\n",
            "Failed line: \n",
            "Failed code line:    return Summary\n",
            "failed tokenization qid: (37395745, 0)\n",
            "Failed line: \n",
            "Failed code line:     output.write(\"\\n\")\n",
            "failed tokenization qid: (4044353, 0)\n",
            "Failed line: \n",
            "Failed code line:   \"\"\"string one's end isn't here; \\\"\"\" it's here \"\"\" \"\"\"string two here\"\"\"\n",
            "failed tokenization qid: (21490597, 0)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (28364131, 0)\n",
            "Failed line: \n",
            "Failed code line:             output.write(i)\n",
            "failed tokenization qid: (30506809, 0)\n",
            "Failed line: \n",
            "Failed code line: t1=[n for n,k in G.out_degree_iter() if k==2\n",
            "failed tokenization qid: (4694316, 0)\n",
            "Failed line: \n",
            "Failed code line: torsion[idx] = tt[idx] / tb[idx]\n",
            "failed tokenization qid: (19608875, 1)\n",
            "17000\n",
            "Failed line: \n",
            "Failed code line:     print(prod, variants)\n",
            "failed tokenization qid: (36454322, 5)\n",
            "Failed line: \n",
            "Failed code line: str = str.replace(/(^[ '\\^\\$\\*#&]+)|([ '\\^\\$\\*#&]+$)/g, '')\n",
            "failed tokenization qid: (20890687, 1)\n",
            "Failed line: \n",
            "Failed code line: health = wordfont.render(\"Your health: %s\" % self.a), 1, (255, 9, 12))\n",
            "failed tokenization qid: (15744983, 2)\n",
            "Failed line: \n",
            "Failed code line: tk.Button(..., command=functools.partial(runprog,route)\n",
            "failed tokenization qid: (15986226, 1)\n",
            "Failed line: \n",
            "Failed code line:         IPrange = 0\n",
            "failed tokenization qid: (32486522, 0)\n",
            "Failed line: \n",
            "Failed code line:                            2016-04-12 10:56:26                     225     235\n",
            "failed tokenization qid: (37679720, 0)\n",
            "Failed line: \n",
            "Failed code line:         return e.output\n",
            "failed tokenization qid: (31150697, 5)\n",
            "Failed line: \n",
            "Failed code line:         self.name = name\n",
            "Failed line: \n",
            "Failed code line:        self.marks = marks\n",
            "failed tokenization qid: (29048744, 0)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (28781476, 0)\n",
            "Failed line: \n",
            "Failed code line:        outfile.write(\"\\n\".join(d[1]) + \"\\n\")\n",
            "failed tokenization qid: (17452831, 3)\n",
            "Failed line: \n",
            "Failed code line: WRAP_FOO(3)\n",
            "failed tokenization qid: (25246440, 1)\n",
            "Failed line: \n",
            "Failed code line:     unicodecsv.reader(f, encoding='utf-8'\n",
            "failed tokenization qid: (31346322, 1)\n",
            "Failed line: \n",
            "Failed code line:           a                \n",
            "failed tokenization qid: (30674708, 1)\n",
            "18000\n",
            "Failed line: \n",
            "Failed code line:     #enter name-value pairs within the employee object - for e.g. let's say the second element after the split is the emp name, the third the age\n",
            "failed tokenization qid: (18099743, 0)\n",
            "Failed line: \n",
            "Failed code line: print (ws['A1'].value\n",
            "failed tokenization qid: (35693094, 1)\n",
            "Failed line: \n",
            "Failed code line:         d[k]+='|' + v\n",
            "failed tokenization qid: (28145180, 5)\n",
            "Failed line: \n",
            "Failed code line:         or ((' ' + small_sentence + ' ') in large_sentence)\n",
            "failed tokenization qid: (25008019, 1)\n",
            "Failed line: \n",
            "Failed code line:                 outFile.write(\"\\t\".join([elem.strip() for elem in line]))\n",
            "failed tokenization qid: (17902268, 3)\n",
            "Failed line: \n",
            "Failed code line: form = YourForm(..., initial={'your_field': request.META['REMOTE_ADDR'])\n",
            "failed tokenization qid: (7545570, 0)\n",
            "Failed line: \n",
            "Failed code line: ^(?=[^']*'[^']*$).*$\n",
            "failed tokenization qid: (27295807, 1)\n",
            "Failed line: \n",
            "Failed code line: [^()]*  # matches 0 or more of any char that is not ( and )\n",
            "failed tokenization qid: (36244815, 1)\n",
            "Failed line: \n",
            "Failed code line: 3 E1 to D1, E1 to F2\n",
            "failed tokenization qid: (32754295, 0)\n",
            "Failed line: \n",
            "Failed code line:     setattr(Klass, method_name, lambda self, val=method_value:val))\n",
            "failed tokenization qid: (33134609, 2)\n",
            "Failed line: \n",
            "Failed code line: print(\"{0!r}\".format(escape_bs_and_ff(\"\\b\\f\"))\n",
            "failed tokenization qid: (10519914, 1)\n",
            "Failed line: \n",
            "Failed code line:     print('class ' + ' & '.join(ln) + r'\\\\')\n",
            "failed tokenization qid: (30832156, 1)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (28049257, 1)\n",
            "19000\n",
            "Failed line: \n",
            "Failed code line:         l = [map(int, line.strip()) for line in f]\n",
            "failed tokenization qid: (26865068, 0)\n",
            "Failed line: \n",
            "Failed code line: freqs = lambda s: filter(lambda count: count > 1, map(s.count, set(s))\n",
            "failed tokenization qid: (25029172, 4)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (24674153, 0)\n",
            "Failed line: \n",
            "Failed code line:     print(locals()['c'])\n",
            "failed tokenization qid: (36355431, 0)\n",
            "Failed line: \n",
            "Failed code line: (?![^()]*\\))(\\d+-\\d+)\n",
            "failed tokenization qid: (29917127, 0)\n",
            "Failed line: \n",
            "Failed code line: Out[5]: ['q_igg', 'q_hcp', 'c_igg', 'c_hcp'\n",
            "failed tokenization qid: (27129152, 0)\n",
            "Failed line: \n",
            "Failed code line:         f.write(line.replace(\"201\", \"202\")))\n",
            "failed tokenization qid: (27850610, 1)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (31319532, 1)\n",
            "Failed line: \n",
            "Failed code line:               9      10    hours from UTC*           0..13\n",
            "failed tokenization qid: (4571899, 0)\n",
            "Failed line: \n",
            "Failed code line:        return cursor\n",
            "failed tokenization qid: (14967880, 1)\n",
            "Failed line: \n",
            "Failed code line: [<MyClass: object1, Tom, 10>, <MyClass: object2, John, 13>]\n",
            "failed tokenization qid: (24191981, 4)\n",
            "Failed line: \n",
            "Failed code line: [None] + sorted([x for x in os.listdir(\"T:\\\\\") if certain_condition(x)]\n",
            "failed tokenization qid: (22301693, 0)\n",
            "20000\n",
            "Failed line: \n",
            "Failed code line: ...\n",
            "failed tokenization qid: (1708103, 0)\n",
            "Failed line: \n",
            "Failed code line: tcprelay2 = subprocess.Popen([\"tcprelay\", \"--portoffset [arg1] [arg2]\")\n",
            "failed tokenization qid: (25815078, 1)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (33318208, 0)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (23542843, 2)\n",
            "Failed line: \n",
            "Failed code line:     default = len(arg1)\n",
            "failed tokenization qid: (24876826, 1)\n",
            "Failed line: \n",
            "Failed code line:         name, marks=item.split(',')\n",
            "Failed line: \n",
            "Failed code line:        dictionary[marks].append(name)                               \n",
            "failed tokenization qid: (23977192, 0)\n",
            "Failed line: \n",
            "Failed code line:             self.cards.insert(0, card)\n",
            "failed tokenization qid: (34546775, 0)\n",
            "Failed line: \n",
            "Failed code line:     destination.write(line + \",a\\n\"))\n",
            "failed tokenization qid: (15484494, 1)\n",
            "Failed line: \n",
            "Failed code line:               little lamb           11\n",
            "Failed line: \n",
            "Failed code line:                      Mary           18\n",
            "failed tokenization qid: (7463233, 2)\n",
            "Failed line: \n",
            "Failed code line:     return (0, list(reversed(range(1, num + 1)))\n",
            "failed tokenization qid: (21413431, 3)\n",
            "Failed line: \n",
            "Failed code line:         print(\"Called By Python:\"+ str(p.cmdline())\n",
            "failed tokenization qid: (37678954, 2)\n",
            "Failed line: \n",
            "Failed code line:                 valuestring+=str(value)\n",
            "Failed line: \n",
            "Failed code line:        outputstring+=valuestring+\";\"\n",
            "failed tokenization qid: (35695639, 2)\n",
            "Failed line: \n",
            "Failed code line:           a                \n",
            "failed tokenization qid: (30674708, 2)\n",
            "Failed line: \n",
            "Failed code line:                     return subkey\n",
            "failed tokenization qid: (5297937, 0)\n",
            "Failed line: \n",
            "Failed code line: print \"{} Modified: {}\".format(keyword,  method, vars_str)\n",
            "failed tokenization qid: (22514846, 1)\n",
            "Failed line: \n",
            "Failed code line:         d[k1][k2].extend(vals))\n",
            "failed tokenization qid: (31843416, 2)\n",
            "Failed line: \n",
            "Failed code line: plt.show()\n",
            "failed tokenization qid: (31978879, 1)\n",
            "Failed line: \n",
            "Failed code line: df.applymap(lambda x: x.replace('\"', '')\n",
            "failed tokenization qid: (21491291, 2)\n",
            "21000\n",
            "Failed line: \n",
            "Failed code line: fig.savefig(os.path.join(('Pics2', 'forcing{0}damping{1}omega{2}set2.png'.format(forcing, damping, omega)))\n",
            "failed tokenization qid: (13825719, 1)\n",
            "Failed line: \n",
            "Failed code line: ...\n",
            "failed tokenization qid: (21446017, 0)\n",
            "Failed line: \n",
            "Failed code line: [ 1.124  5.152  6.235  0.     5.124  0.\n",
            "failed tokenization qid: (28817476, 1)\n",
            "Failed line: \n",
            "Failed code line:     return send_from_directory(path, filename)\n",
            "failed tokenization qid: (21390104, 1)\n",
            "Failed line: \n",
            "Failed code line:         f.write(astr)\n",
            "failed tokenization qid: (34511694, 5)\n",
            "Failed line: \n",
            "Failed code line:     writer.writerows(all)\n",
            "failed tokenization qid: (28999222, 0)\n",
            "Failed line: \n",
            "Failed code line: ids = set([str(x[5]) for x in text_results] + [str(x[4]) for x in doc_results]))\n",
            "failed tokenization qid: (27503621, 2)\n",
            "Failed line: \n",
            "Failed code line:         Right = True\n",
            "failed tokenization qid: (30335805, 0)\n",
            "Failed line: \n",
            "Failed code line: nowest = now.replace(tzinfo(EST())\n",
            "failed tokenization qid: (19227798, 3)\n",
            "Failed line: \n",
            "Failed code line:     b[index]=a[index]\n",
            "failed tokenization qid: (28283816, 0)\n",
            "Failed line: \n",
            "Failed code line: image.save('output.jpg')\n",
            "failed tokenization qid: (7793186, 1)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (1253122, 2)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (33775695, 0)\n",
            "Failed line: \n",
            "Failed code line:                        roc                \n",
            "failed tokenization qid: (30568995, 0)\n",
            "Failed line: \n",
            "Failed code line:      print(self.eixo + str(self.zero+5))\n",
            "failed tokenization qid: (36726716, 1)\n",
            "Failed line: \n",
            "Failed code line: {% endif %}\n",
            "failed tokenization qid: (17110113, 3)\n",
            "Failed line: \n",
            "Failed code line:     sums.append(sum(x*y for x, y in zip(list1_choices, list2))\n",
            "failed tokenization qid: (17797973, 0)\n",
            "Failed line: \n",
            "Failed code line: data.sort(key=lambda s:(s['identity'],s['time']))\n",
            "failed tokenization qid: (10972925, 1)\n",
            "Failed line: \n",
            "Failed code line:     lis.append((k, sum(items)/len(items), len(items)))\n",
            "failed tokenization qid: (16135174, 0)\n",
            "Failed line: \n",
            "Failed code line: ## in this case, len(result) == 3\n",
            "failed tokenization qid: (35421378, 0)\n",
            "Failed line: \n",
            "Failed code line: {'message': {'status': {'time': 50}, 'code': {'response': 80}}, 'time': 100}\n",
            "failed tokenization qid: (25389875, 1)\n",
            "22000\n",
            "Failed line: \n",
            "Failed code line:     my_list[i] += 1\n",
            "failed tokenization qid: (28895599, 2)\n",
            "Failed line: \n",
            "Failed code line:     subprocess.Popen([shell, d])\n",
            "failed tokenization qid: (1795111, 2)\n",
            "Failed line: \n",
            "Failed code line:   #And then actually do the work\n",
            "failed tokenization qid: (20021051, 0)\n",
            "Failed line: \n",
            "Failed code line: ['+ ', ['-', 5, 4], ['-', 2, 1]]\n",
            "failed tokenization qid: (27176445, 0)\n",
            "Failed line: \n",
            "Failed code line:      ... do something, like sorting..\n",
            "failed tokenization qid: (36339557, 0)\n",
            "Failed line: \n",
            "Failed code line:     b.append(tuple(chord_length))\n",
            "failed tokenization qid: (37682744, 1)\n",
            "Failed line: \n",
            "Failed code line: ['a', '4'], ['c', '7'], ['b', '17'], ['f', '11'], ['f', '12']]\n",
            "failed tokenization qid: (30855559, 0)\n",
            "Failed line: \n",
            "Failed code line: print('Sums: {} \\noverall sum: {}'.format(*avg_grams((a, b))))\n",
            "failed tokenization qid: (33466515, 0)\n",
            "Failed line: \n",
            "Failed code line: print \"$matched_string\\n\";\n",
            "failed tokenization qid: (3332442, 0)\n",
            "Failed line: \n",
            "Failed code line: }\n",
            "failed tokenization qid: (20586981, 1)\n",
            "Failed line: \n",
            "Failed code line:     ... #blit the waterimg, but don't flip\n",
            "failed tokenization qid: (4417108, 0)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (22107328, 2)\n",
            "23000\n",
            "Failed line: \n",
            "Failed code line:         \"\"\"Read a line. Terribly naive. Do not use at home\"\n",
            "Failed position: 7\n",
            "wordpunct_tokenizer tokenization: \n",
            "['\"\"\"', 'Read', 'a', 'line', '.', 'Terribly', 'naive', '.', 'Do', 'not', 'use', 'at', 'home', '\"']\n",
            "failed tokenization qid: (9047810, 0)\n",
            "Failed line: \n",
            "Failed code line:        ...\n",
            "failed tokenization qid: (26994563, 0)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (10277318, 0)\n",
            "Failed line: \n",
            "Failed code line: \\([^)]*\\)|([^a-z()]+)\n",
            "failed tokenization qid: (24597126, 0)\n",
            "Failed line: \n",
            "Failed code line:     line1  line2  line3   name\n",
            "failed tokenization qid: (34670679, 0)\n",
            "Failed line: \n",
            "Failed code line: done\n",
            "failed tokenization qid: (24794182, 1)\n",
            "Failed line: \n",
            "Failed code line:                         tmp.write(line)\n",
            "failed tokenization qid: (24064857, 2)\n",
            "Failed line: \n",
            "Failed code line:         return Matrix.map(lambda a,b,**kw:a+b, self, other)\n",
            "failed tokenization qid: (6382705, 2)\n",
            "Failed line: \n",
            "Failed code line: sum(1 for _ in itertools.takewhile(lambda x: x=='0',reversed(string))\n",
            "failed tokenization qid: (16952084, 1)\n",
            "Failed line: \n",
            "Failed code line:     bg.save()\n",
            "failed tokenization qid: (10373711, 1)\n",
            "24000\n",
            "Failed line: \n",
            "Failed code line:     fun(arr[tuple([slice(N),slice(N)...,i])]\n",
            "failed tokenization qid: (35433778, 2)\n",
            "Failed line: \n",
            "Failed code line: client.loop_forever()\n",
            "failed tokenization qid: (37420612, 0)\n",
            "Failed line: \n",
            "Failed code line:               9 LOAD_CONST               2 (1)\n",
            "failed tokenization qid: (28509261, 0)\n",
            "Failed line: \n",
            "Failed code line: A-Z]+)'\n",
            "failed tokenization qid: (7634341, 0)\n",
            "Failed line: \n",
            "Failed code line:         self._track = value\n",
            "failed tokenization qid: (17344217, 2)\n",
            "Failed line: \n",
            "Failed code line: df_merged4['CHAIN_LENGTH'] = df_merged4.drop(['PED','1_EFF','2_EFF','3_EFF','4_EFF','5_EFF'], axis=1).apply(lambda row: len(pd.unique(row)), axis=1) -3\n",
            "failed tokenization qid: (31127870, 1)\n",
            "Failed line: \n",
            "Failed code line: )\n",
            "failed tokenization qid: (24695092, 2)\n",
            "Failed line: \n",
            "Failed code line: 'http://my-cdn-path.com/' + '/'.join(i.split('/')[-4:]))\n",
            "failed tokenization qid: (18113560, 0)\n",
            "Failed line: \n",
            "Failed code line:                 continue\n",
            "Failed line: \n",
            "Failed code line:         print(\"Seat unavailable\\n\")\n",
            "failed tokenization qid: (27707264, 1)\n",
            "Failed line: \n",
            "Failed code line:         print (food.keys()) # see just the keys\n",
            "failed tokenization qid: (25149224, 1)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (20168251, 0)\n",
            "Failed line: \n",
            "Failed code line: \\)\\s*(\\D+)\\s\\d\n",
            "failed tokenization qid: (26917886, 0)\n",
            "Failed line: \n",
            "Failed code line: # result\n",
            "failed tokenization qid: (19945091, 0)\n",
            "Failed line: \n",
            "Failed code line: 200\n",
            "failed tokenization qid: (29421840, 2)\n",
            "Failed line: \n",
            "Failed code line:     # do something with match\n",
            "failed tokenization qid: (16186388, 2)\n",
            "Failed line: \n",
            "Failed code line: glob.glob(\"/path_to/File [0-9]*.csv\"))\n",
            "failed tokenization qid: (37689986, 1)\n",
            "Failed line: \n",
            "Failed code line: input_RDD.map(lambda x: (x[1][0],(x[0],x[1][1]))\n",
            "failed tokenization qid: (36504383, 1)\n",
            "Failed line: \n",
            "Failed code line:     self.color_cycle = itertools.cycle(clist\n",
            "failed tokenization qid: (24193174, 0)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (32486522, 1)\n",
            "Failed line: \n",
            "Failed code line:     points.append((x, func(x))\n",
            "failed tokenization qid: (25675354, 0)\n",
            "Failed line: \n",
            "Failed code line:         fout.write('{} {}\\n'.format(max_score, name)\n",
            "failed tokenization qid: (28234890, 0)\n",
            "25000\n",
            "Failed line: \n",
            "Failed code line:     print (k, v)\n",
            "failed tokenization qid: (33384673, 1)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (29850757, 1)\n",
            "Failed line: \n",
            "Failed code line:    (['zit', '10', 'popcorn', '6', 'pimple', '6', 'cherry', '5'], 'aaron popped', 27)]\n",
            "failed tokenization qid: (20006972, 0)\n",
            "Failed line: \n",
            "Failed code line:                 5                   3           2              \n",
            "Failed line: \n",
            "Failed code line:                                        6                         \n",
            "failed tokenization qid: (26796493, 1)\n",
            "Failed line: \n",
            "Failed code line:                 return row, index + 1\n",
            "failed tokenization qid: (26913877, 1)\n",
            "Failed line: \n",
            "Failed code line: done < <(find $search  -maxdepth 1 -name '*.html')\n",
            "failed tokenization qid: (18377549, 0)\n",
            "Failed line: \n",
            "Failed code line:         d += timedelta(days=1)\n",
            "failed tokenization qid: (32725151, 1)\n",
            "Failed line: \n",
            "Failed code line:     top_buttons.add_widget(save=Button(text='Save')\n",
            "failed tokenization qid: (37092670, 0)\n",
            "Failed line: \n",
            "Failed code line: print(sum(heapq.nlargest(2,b))\n",
            "failed tokenization qid: (36256009, 1)\n",
            "Failed line: \n",
            "Failed code line:              if line[3] != '')\n",
            "failed tokenization qid: (12591850, 2)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (18822727, 2)\n",
            "Failed line: \n",
            "Failed code line:                 i += 1                                                      \n",
            "failed tokenization qid: (15509905, 1)\n",
            "Failed line: \n",
            "Failed code line: xyz_list.count(i)) #  0(n) operation\n",
            "failed tokenization qid: (28393210, 0)\n",
            "Failed line: \n",
            "Failed code line:     dic[x[0]].append(x[1:])\n",
            "failed tokenization qid: (13900106, 2)\n",
            "26000\n",
            "Failed line: \n",
            "Failed code line: indices = list(combinations(range(n), r=ndim)\n",
            "failed tokenization qid: (28856137, 0)\n",
            "Failed line: \n",
            "Failed code line:               9 CALL_FUNCTION            2\n",
            "failed tokenization qid: (2909423, 0)\n",
            "Failed line: \n",
            "Failed code line: ^(.*)&&&&.*?@([A-Za-z0-9([A-Za-z0-9_]+)\n",
            "failed tokenization qid: (31557657, 1)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (33689631, 2)\n",
            "Failed line: \n",
            "Failed code line: eval('f%d'%inp)\n",
            "failed tokenization qid: (19227002, 2)\n",
            "Failed line: \n",
            "Failed code line:         self.connection.write(':MOV:REL {0:d} {1:d} {2:d} {3:d}'.format(self.id, dx, dy, dz)\n",
            "failed tokenization qid: (18903446, 0)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (7260370, 1)\n",
            "Failed line: \n",
            "Failed code line: out_file.write(text)\n",
            "failed tokenization qid: (8454543, 2)\n",
            "Failed line: \n",
            "Failed code line:     writer.writerow(d)\n",
            "failed tokenization qid: (21989448, 1)\n",
            "Failed line: \n",
            "Failed code line: \\[(?P<string1>[^\\]]*)\\]\\s*(?P<string2>[^()]*)(?:\\s+\\((?P<string3>.*)\\))?$\n",
            "failed tokenization qid: (36244815, 0)\n",
            "Failed line: \n",
            "Failed code line:      # Otherwise, pop up a level, search again\n",
            "failed tokenization qid: (24919591, 1)\n",
            "Failed line: \n",
            "Failed code line: ${post.date.strftime('%Y/%m/%d %H:%M')\n",
            "failed tokenization qid: (14101045, 0)\n",
            "Failed line: \n",
            "Failed code line:         wr.writerow(list(filter(None, line.rstrip().translate(table).split(\",\"))\n",
            "failed tokenization qid: (28461458, 3)\n",
            "Failed line: \n",
            "Failed code line:                 d[word].append((i, j)\n",
            "failed tokenization qid: (36390268, 2)\n",
            "Failed line: \n",
            "Failed code line:     main()\n",
            "failed tokenization qid: (25160114, 0)\n",
            "Failed line: \n",
            "Failed code line: [[0], [0, 1], [0, 2], [0, 3], [0, 4], [0, 1, 2], [0, 1, 3], [0, 2, 3], [0, 1, 4], [0, 2, 4], [0, 3, 4], [0, 1, 2, 3], [0, 1, 2, 4], [0, 1, 3, 4], [0, 2, 3, 4], [0, 1, 2, 3, 4]]\n",
            "failed tokenization qid: (18334906, 1)\n",
            "Failed line: \n",
            "Failed code line:     update.append((zparam, zparam + tr_rate*(x - vis))\n",
            "failed tokenization qid: (34908928, 1)\n",
            "Failed line: \n",
            "Failed code line: a,b = map(int,inp)\n",
            "failed tokenization qid: (28432679, 0)\n",
            "27000\n",
            "Failed line: \n",
            "Failed code line:      })\n",
            "failed tokenization qid: (21690567, 2)\n",
            "Failed line: \n",
            "Failed code line:         out.append(dict(zip(names, a.split(None, 7) + [b])))]\n",
            "failed tokenization qid: (32510653, 0)\n",
            "Failed line: \n",
            "Failed code line: >>> [(0, 0.1, 0.2, 0.3, 0.4), (0, 0.1, 0.2, 0.4, 0.3), (0, 0.1, 0.3, 0.2, 0.4), (0, 0.1, 0.3, 0.4, 0.2), (0, 0.1, 0.4, 0.2, 0.3), (0, 0.1, 0.4, 0.3, 0.2), (0, 0.1, 0.4, 0.5), (0, 0.1, 0.4, 0.5), (0, 0.1, 0.5, 0.4), (0, 0.1, 0.5, 0.4), (0, 0.2, 0.1, 0.3, 0.4), (0, 0.2 ...\n",
            "failed tokenization qid: (22841469, 1)\n",
            "Failed line: \n",
            "Failed code line:         print (v, row['var2'], row['var3'])\n",
            "failed tokenization qid: (24419551, 1)\n",
            "Failed line: \n",
            "Failed code line:     5 NaN NaN\n",
            "failed tokenization qid: (12390336, 1)\n",
            "Failed line: \n",
            "Failed code line: index = min(range(len(lst)), key=lambda dx: len(lst[dx][2])\n",
            "failed tokenization qid: (28974582, 1)\n",
            "Failed line: \n",
            "Failed code line:     x = x+1\n",
            "failed tokenization qid: (26288518, 2)\n",
            "Failed line: \n",
            "Failed code line: h.show_info()\n",
            "failed tokenization qid: (30563167, 2)\n",
            "Failed line: \n",
            "Failed code line:         print \"Have\", want, \"in some listB item\"\n",
            "failed tokenization qid: (35567243, 0)\n",
            "Failed line: \n",
            "Failed code line:         queue.append([front.left, path + \"->\" + str(front.left.val)])\n",
            "failed tokenization qid: (32261317, 0)\n",
            "Failed line: \n",
            "Failed code line: qs = Question.objects.exclude(choice=None).order_by'(-pub_date')[:5]\n",
            "failed tokenization qid: (28088164, 0)\n",
            "Failed line: \n",
            "Failed code line: print(x.title() + \" -  Small: $\" + int(tiles[x])/2 + \"  Medium: $\" + tiles[x] + \"  Large: $\" + int(tiles[x])*(2)\n",
            "failed tokenization qid: (32498589, 0)\n",
            "Failed line: \n",
            "Failed code line:         print(elem, end=' ')\n",
            "failed tokenization qid: (16224200, 1)\n",
            "28000\n",
            "Failed line: \n",
            "Failed code line: print sorted(big_array,key=lambda x:datetime.datetime.strptime(x[1],\"%d-%m-%Y\")\n",
            "failed tokenization qid: (21584000, 1)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (37048952, 2)\n",
            "Failed line: \n",
            "Failed code line: print (\"Welcome in\"))\n",
            "failed tokenization qid: (11318010, 0)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (36021944, 1)\n",
            "Failed line: \n",
            "Failed code line: # (+1 +2 -4 +5 -3)\n",
            "failed tokenization qid: (21132397, 1)\n",
            "Failed line: \n",
            "Failed code line:             f.write(requests.get(lnk).content\n",
            "failed tokenization qid: (37158246, 1)\n",
            "Failed line: \n",
            "Failed code line: plt.subplots_adjust(right=0.95)\n",
            "failed tokenization qid: (8888240, 3)\n",
            "Failed line: \n",
            "Failed code line:         return [\"%s%s\" % (prefix,i)  for i in range(n)]\n",
            "failed tokenization qid: (24807588, 0)\n",
            "Failed line: \n",
            "Failed code line: maxes = [ele for ele in lst if ele[1] == mx[1]]\n",
            "failed tokenization qid: (31608321, 0)\n",
            "Failed line: \n",
            "Failed code line: dict_cursor = lambda c, d: dict(zip(d, r) for r in c))\n",
            "failed tokenization qid: (2678991, 1)\n",
            "Failed line: \n",
            "Failed code line:     user_data = dict([(record['Name'], record['phone']) for record in reader if record.get('phone').strip())\n",
            "failed tokenization qid: (36391559, 0)\n",
            "Failed line: \n",
            "Failed code line: assert my_lst == [1, 2, 3]\n",
            "failed tokenization qid: (13414366, 1)\n",
            "Failed line: \n",
            "Failed code line:     )\n",
            "failed tokenization qid: (35840717, 2)\n",
            "Failed line: \n",
            "Failed code line:                     break\n",
            "Failed line: \n",
            "Failed code line:                  prev = line\n",
            "failed tokenization qid: (28898384, 1)\n",
            "Failed line: \n",
            "Failed code line: all_combinations = list(product_with_combo(product_with_validation, [1,2,3],[1,2,3])\n",
            "failed tokenization qid: (18529762, 0)\n",
            "Failed line: \n",
            "Failed code line: });\n",
            "failed tokenization qid: (20842293, 0)\n",
            "Failed line: \n",
            "Failed code line:     print(\"{} - {}: {}\".format(i, name, score)\n",
            "failed tokenization qid: (36572993, 2)\n",
            "Failed line: \n",
            "Failed code line: ('AccName', 'S'), ('Balance', 'N'), ('AccrInterest', 'N'), ('foo', '')]\n",
            "failed tokenization qid: (29251843, 1)\n",
            "Failed line: \n",
            "Failed code line:         print(\"yes\")\n",
            "failed tokenization qid: (5707875, 1)\n",
            "Failed line: \n",
            "Failed code line:     return send_from_directory(path, files[0])\n",
            "failed tokenization qid: (21390104, 2)\n",
            "29000\n",
            "Failed line: \n",
            "Failed code line:       + ('%s\\t%s\\t\\n' % (itn(),itn()) if b==2\n",
            "Failed line: \n",
            "Failed code line:          else '')\n",
            "failed tokenization qid: (13655116, 0)\n",
            "Failed line: \n",
            "Failed code line:         strings.append('0' + s)\n",
            "failed tokenization qid: (27367867, 0)\n",
            "Failed line: \n",
            "Failed code line:         return k,str(v)\n",
            "Failed line: \n",
            "Failed code line:     argv.extend(foo(k,v))\n",
            "failed tokenization qid: (33893970, 2)\n",
            "Failed line: \n",
            "Failed code line:     ggplot2.coord_flip()\n",
            "failed tokenization qid: (15274630, 1)\n",
            "Failed line: \n",
            "Failed code line:        subject_nr      condition  count_trial_sequence  trial_id choice accuracy  \n",
            "failed tokenization qid: (21258343, 4)\n",
            "Failed line: \n",
            "Failed code line: {% set name_sanitized = _name_sanitized[''] %}\n",
            "failed tokenization qid: (33465542, 3)\n",
            "Failed line: \n",
            "Failed code line:         counter += 1\n",
            "failed tokenization qid: (35654781, 3)\n",
            "Failed line: \n",
            "Failed code line:  #Quit\n",
            "failed tokenization qid: (37401372, 1)\n",
            "Failed line: \n",
            "Failed code line: weights[section]*(1/(num_empty(board)+1)))\n",
            "failed tokenization qid: (29924651, 0)\n",
            "Failed line: \n",
            "Failed code line:           .\n",
            "failed tokenization qid: (24237967, 1)\n",
            "Failed line: \n",
            "Failed code line: text = reduce(lambda txt, repl: repl(txt), REPLACEMENTS, str(row[0])\n",
            "failed tokenization qid: (22330551, 5)\n",
            "Failed line: \n",
            "Failed code line: # ImplementationError since `grouped['col1']` does not implement __getitem__\n",
            "failed tokenization qid: (36293886, 6)\n",
            "30000\n",
            "Failed line: \n",
            "Failed code line: print mylist\n",
            "failed tokenization qid: (22024727, 0)\n",
            "Failed line: \n",
            "Failed code line: (2.9, 3.1)\n",
            "failed tokenization qid: (27216168, 2)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (28398672, 0)\n",
            "Failed line: \n",
            "Failed code line:               9 CALL_FUNCTION            1\n",
            "failed tokenization qid: (25626694, 0)\n",
            "Failed line: \n",
            "Failed code line:         print command.tag, command.attrib, subs[0].tag, subs[0].attrib\n",
            "failed tokenization qid: (17407390, 0)\n",
            "Failed line: \n",
            "Failed code line:         or (large_sentence.endswith(' ' + small_sentence):\n",
            "failed tokenization qid: (25008019, 0)\n",
            "Failed line: \n",
            "Failed code line:     return all(samevalue(a[x], b[x]) for x in a))\n",
            "failed tokenization qid: (3860009, 8)\n",
            "Failed line: \n",
            "Failed code line: print classifier.classify(three_split(\"Jim Silva\"))\n",
            "failed tokenization qid: (29437467, 7)\n",
            "Failed line: \n",
            "Failed code line: pprint(OD)\n",
            "failed tokenization qid: (15720793, 4)\n",
            "Failed line: \n",
            "Failed code line: format_spec ::=  [[fill]align][sign][#][0][width][.precision][type]\n",
            "failed tokenization qid: (23530798, 5)\n",
            "31000\n",
            "Failed line: \n",
            "Failed code line:                                                  1_______\n",
            "Failed line: \n",
            "Failed code line:                                        2__________________\n",
            "Failed line: \n",
            "Failed code line:                       7_______\n",
            "Failed line: \n",
            "Failed code line:             8__________________\n",
            "Failed line: \n",
            "Failed code line: 9 assign to foo at index from step 8 from right hand side of tuple from step 5\n",
            "failed tokenization qid: (20106963, 1)\n",
            "Failed line: \n",
            "Failed code line:     print r.id, r.name, r.area\n",
            "failed tokenization qid: (17650896, 1)\n",
            "Failed line: \n",
            "Failed code line:  ('a,b,c', 5)]\n",
            "failed tokenization qid: (25266620, 1)\n",
            "Failed line: \n",
            "Failed code line: print \"No data matches your search query. Please try again\"\n",
            "failed tokenization qid: (2824360, 2)\n",
            "Failed line: \n",
            "Failed code line:     d2['%s:%d' % (key, len(values)] = ' '.join(str(v) for v in values)\n",
            "failed tokenization qid: (2122880, 1)\n",
            "Failed line: \n",
            "Failed code line:    outfile.write(' '.join([str(i) for i in pixels])\n",
            "failed tokenization qid: (30617939, 1)\n",
            "32000\n",
            "Failed line: \n",
            "Failed code line: print(add)\n",
            "failed tokenization qid: (34559695, 0)\n",
            "Failed line: \n",
            "Failed code line:     d=defaultdict(int)\n",
            "failed tokenization qid: (12268526, 0)\n",
            "Failed line: \n",
            "Failed code line:               9 JUMP_IF_FALSE_OR_POP    15\n",
            "Failed line: \n",
            "Failed code line:              12 LOAD_FAST                2 (c)\n",
            "Failed line: \n",
            "Failed code line:               9 JUMP_IF_FALSE_OR_POP    15\n",
            "Failed line: \n",
            "Failed code line:              12 LOAD_FAST                2 (c)\n",
            "failed tokenization qid: (19377963, 2)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (32592957, 1)\n",
            "Failed line: \n",
            "Failed code line: dict((key, np.array(val) if key not in {'C', 'D'} else val for key, val in myDict.iteritems())\n",
            "failed tokenization qid: (18480990, 1)\n",
            "Failed line: \n",
            "Failed code line: to_insert = set(values) - available_values\n",
            "failed tokenization qid: (2438690, 1)\n",
            "Failed line: \n",
            "Failed code line: (timeNow, err) = proc.communicate()\n",
            "failed tokenization qid: (27464957, 1)\n",
            "Failed line: \n",
            "Failed code line:     pass # your code here\n",
            "failed tokenization qid: (25561186, 3)\n",
            "Failed line: \n",
            "Failed code line: F = [[0 for x in xrange(len(A)] for x in xrange(len(B))]\n",
            "failed tokenization qid: (22951162, 0)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (33227216, 0)\n",
            "Failed line: \n",
            "Failed code line:             0\n",
            "failed tokenization qid: (36537945, 2)\n",
            "33000\n",
            "Failed line: \n",
            "Failed code line: [6, 3, 4, 4, 7, 6, 2, 3, 8, 11, 10, 8]\n",
            "failed tokenization qid: (28278951, 1)\n",
            "Failed line: \n",
            "Failed code line:             raise ValueError('invalid closure pattern: {!r}'.format(closure_pattern))\n",
            "failed tokenization qid: (33550674, 0)\n",
            "Failed line: \n",
            "Failed code line:    'l': '59', 'dic1.g': '10', 'dic2.g': '55'}\n",
            "failed tokenization qid: (21944875, 2)\n",
            "Failed line: \n",
            "Failed code line:             A                   B         D\n",
            "failed tokenization qid: (14529838, 1)\n",
            "Failed line: \n",
            "Failed code line:                  5  2       5  3      5  4    5  5    5  6\n",
            "Failed line: \n",
            "Failed code line:                                   6                         \n",
            "Failed line: \n",
            "Failed code line:                          6     x                          \n",
            "Failed line: \n",
            "Failed code line:           5    5                5    3       5    2      5           \n",
            "Failed line: \n",
            "Failed code line:                                6         6                             \n",
            "Failed line: \n",
            "Failed code line:             5           3       2          \n",
            "Failed line: \n",
            "Failed code line:                            6                 \n",
            "failed tokenization qid: (26796493, 0)\n",
            "Failed line: \n",
            "Failed code line:  if any(x % i == 0 for i in (2, 3, 5, 7, 11, 13, 17, 19, 23)]\n",
            "failed tokenization qid: (25457015, 1)\n",
            "Failed line: \n",
            "Failed code line:         raise IntegrityError(\"Error message\")\n",
            "failed tokenization qid: (10576797, 0)\n",
            "Failed line: \n",
            "Failed code line:     return matchdict\n",
            "failed tokenization qid: (25150895, 0)\n",
            "Failed line: \n",
            "Failed code line: array([8, 9])\n",
            "failed tokenization qid: (24895913, 0)\n",
            "Failed line: \n",
            "Failed code line:     top_buttons.add_widget(save=Button(text='Save')\n",
            "failed tokenization qid: (37092670, 1)\n",
            "Failed line: \n",
            "Failed code line:     iPhase = iPhase+1\n",
            "failed tokenization qid: (21747763, 0)\n",
            "Failed line: \n",
            "Failed code line:          outputlist.append((word1, word2))\n",
            "failed tokenization qid: (32588353, 1)\n",
            "Failed line: \n",
            "Failed code line:             scores[sequence] = str(int(old_score) + int(score))\n",
            "failed tokenization qid: (18969034, 1)\n",
            "Failed line: \n",
            "Failed code line:     my_dict=dict(x.strip().split(\":\") for x in fd)\n",
            "failed tokenization qid: (16376888, 0)\n",
            "Failed line: \n",
            "Failed code line:      })\n",
            "failed tokenization qid: (21690567, 0)\n",
            "Failed line: \n",
            "Failed code line: self.response.write(json.dumps(my_list)\n",
            "failed tokenization qid: (14799223, 0)\n",
            "Failed line: \n",
            "Failed code line: print(f)\n",
            "failed tokenization qid: (26556676, 0)\n",
            "Failed line: \n",
            "Failed code line:             temp.append(+1.0)\n",
            "failed tokenization qid: (34253448, 0)\n",
            "Failed line: \n",
            "Failed code line: ^(.*)&&&&.*@([A-Za-z0-9([A-Za-z0-9_]+)\n",
            "failed tokenization qid: (31557657, 0)\n",
            "Failed line: \n",
            "Failed code line:                                         yield element\n",
            "Failed line: \n",
            "Failed code line:         print \",\".join(str(dic[y.strip()]) for y in x)\n",
            "failed tokenization qid: (13412248, 2)\n",
            "34000\n",
            "Failed line: \n",
            "Failed code line: def\\s+(?=[a-z]+(?:[A-Z][a-z0-9]+)+\\s*\\().*?\\(\n",
            "failed tokenization qid: (6512027, 1)\n",
            "Failed line: \n",
            "Failed code line:               9 POP_TOP             \n",
            "Failed line: \n",
            "Failed code line: \n",
            "Failed line: \n",
            "Failed code line:               9 POP_TOP             \n",
            "Failed line: \n",
            "Failed code line:              10 JUMP_FORWARD             0 (to 13)\n",
            "failed tokenization qid: (22865572, 1)\n",
            "Failed line: \n",
            "Failed code line:                                     random.choice(headlines).split(\" \"))[1:-1]))\n",
            "failed tokenization qid: (34418934, 1)\n",
            "Failed line: \n",
            "Failed code line: [(i, val) for i, val in enumerate([[4,6,7,21,1,7,3]) if val <= 4]\n",
            "failed tokenization qid: (32249907, 0)\n",
            "Failed line: \n",
            "Failed code line: 'a b c d'\n",
            "failed tokenization qid: (33399109, 1)\n",
            "Failed line: \n",
            "Failed code line:     print >> fw, label + ',' + ','.join(map(str, csvrow)\n",
            "failed tokenization qid: (35973562, 2)\n",
            "Failed line: \n",
            "Failed code line: 16\n",
            "failed tokenization qid: (36461053, 0)\n",
            "Failed line: \n",
            "Failed code line: }'\n",
            "failed tokenization qid: (29431716, 1)\n",
            "Failed line: \n",
            "Failed code line: lines = \"\\n\".join(list(itertools.chain.from_iterable(table))\n",
            "failed tokenization qid: (32212182, 2)\n",
            "Failed line: \n",
            "Failed code line:             df.Type.ix[i] = 'A'\n",
            "Failed line: \n",
            "Failed code line:     df.fillna('')\n",
            "Failed line: \n",
            "Failed code line:     df['Type'] = df['Lang'].apply(f)\n",
            "failed tokenization qid: (21308112, 1)\n",
            "Failed line: \n",
            "Failed code line:             self.gl.add_widget(Label(text=str(p['price']))\n",
            "failed tokenization qid: (32097748, 0)\n",
            "Failed line: \n",
            "Failed code line: args.cmd(args.sometext)\n",
            "failed tokenization qid: (37486436, 1)\n",
            "Failed line: \n",
            "Failed code line: sheet = book.sheet_by_name(list(set(['map', 'Map', 'MAP']) & set(book.sheet_names())[0])\n",
            "failed tokenization qid: (10098222, 0)\n",
            "Failed line: \n",
            "Failed code line:     return matchdict\n",
            "failed tokenization qid: (25150895, 1)\n",
            "35000\n",
            "Failed line: \n",
            "Failed code line: g.write(\"{0}, {1}, {2}, {3}, {4}, {5}, {6}\\n\".format(row[0], row[1], row[2], row[3], \"T\", row[5], row[6])\n",
            "failed tokenization qid: (30507699, 1)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (32667256, 0)\n",
            "Failed line: \n",
            "Failed code line: 4.75\n",
            "failed tokenization qid: (27974208, 0)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (17690377, 1)\n",
            "Failed line: \n",
            "Failed code line:   9              \n",
            "failed tokenization qid: (30683166, 2)\n",
            "Failed line: \n",
            "Failed code line:     return result\n",
            "failed tokenization qid: (14124795, 6)\n",
            "Failed line: \n",
            "Failed code line: 1  [b]  [b]\n",
            "failed tokenization qid: (36017405, 0)\n",
            "Failed line: \n",
            "Failed code line:             print next(f)\n",
            "failed tokenization qid: (16047508, 0)\n",
            "Failed line: \n",
            "Failed code line: df.columns = pd.Index(np.arange(1,len(df.columns)+1).astype(str)\n",
            "failed tokenization qid: (37701373, 0)\n",
            "Failed line: \n",
            "Failed code line: value1\n",
            "failed tokenization qid: (29021865, 2)\n",
            "Failed line: \n",
            "Failed code line:               9 STORE_FAST               2 (b)\n",
            "failed tokenization qid: (13649684, 1)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (36021944, 2)\n",
            "Failed line: \n",
            "Failed code line:         print(row_format(\"{}.\".format(idx), *row))\n",
            "failed tokenization qid: (33225630, 4)\n",
            "36000\n",
            "Failed line: \n",
            "Failed code line:             y += 1\n",
            "failed tokenization qid: (17046006, 0)\n",
            "Failed line: \n",
            "Failed code line:       ^^\n",
            "failed tokenization qid: (37378156, 0)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (23246400, 1)\n",
            "Failed line: \n",
            "Failed code line: Parent.fieldname.__get__(self))\n",
            "failed tokenization qid: (31886343, 0)\n",
            "Failed line: \n",
            "Failed code line:     .flatMap(identity))\n",
            "failed tokenization qid: (32980908, 1)\n",
            "Failed line: \n",
            "Failed code line:         users2.write(str(words[1:3])\n",
            "failed tokenization qid: (23641838, 1)\n",
            "Failed line: \n",
            "Failed code line:     main()\n",
            "failed tokenization qid: (34374844, 0)\n",
            "Failed line: \n",
            "Failed code line:     main_list[ind] = substitutions[i]\n",
            "failed tokenization qid: (22053293, 1)\n",
            "Failed line: \n",
            "Failed code line:     # ... etc\n",
            "failed tokenization qid: (22604809, 1)\n",
            "Failed line: \n",
            "Failed code line: connection.request('GET', '/1/users/{0}'.format(VARIABLEHERE),#more stuff\n",
            "failed tokenization qid: (21161458, 1)\n",
            "Failed line: \n",
            "Failed code line:     clean_column_2.append(nested_column_2[i][0])\n",
            "failed tokenization qid: (22674251, 0)\n",
            "Failed line: \n",
            "Failed code line:     return output_string\n",
            "failed tokenization qid: (36949478, 0)\n",
            "37000\n",
            "Failed line: \n",
            "Failed code line: 505578544\n",
            "failed tokenization qid: (26294953, 3)\n",
            "Failed line: \n",
            "Failed code line: 4  0.547791 -0.378287 -1.171706\n",
            "failed tokenization qid: (34659105, 2)\n",
            "Failed line: \n",
            "Failed code line:             self.indexes[i].append( getattr( person, i )\n",
            "failed tokenization qid: (2305798, 2)\n",
            "Failed line: \n",
            "Failed code line:         index += 1\n",
            "failed tokenization qid: (25798730, 0)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (5358800, 0)\n",
            "Failed line: \n",
            "Failed code line:     0           1\n",
            "failed tokenization qid: (33663402, 3)\n",
            "Failed line: \n",
            "Failed code line:     return min(attempts, key=lambda a: len(matching_words(a))))\n",
            "failed tokenization qid: (22506193, 5)\n",
            "Failed line: \n",
            "Failed code line:         outf.write(' '.join(line)+\"\\n\")\n",
            "failed tokenization qid: (23116537, 0)\n",
            "Failed line: \n",
            "Failed code line: kode_prfoksov]  = [a.decode(\"utf-8\") for a in codes_from_file]\n",
            "failed tokenization qid: (9801953, 0)\n",
            "Failed line: \n",
            "Failed code line:     ...\n",
            "failed tokenization qid: (36293886, 7)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (14029010, 3)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (11272806, 0)\n",
            "38000\n",
            "Failed line: \n",
            "Failed code line:     date    id  prev\n",
            "failed tokenization qid: (30741510, 2)\n",
            "Failed line: \n",
            "Failed code line: sorted(yourlst, key=lambda t: (abs(t[0] - t[1])), t[0]), reverse=True)\n",
            "failed tokenization qid: (24579202, 0)\n",
            "Failed line: \n",
            "Failed code line: print max(dates)  #: 2014-06-17\n",
            "failed tokenization qid: (24272337, 0)\n",
            "Failed line: \n",
            "Failed code line:          [ 4.,  4.,  4.]]]]\n",
            "failed tokenization qid: (33768373, 1)\n",
            "Failed line: \n",
            "Failed code line: [(3, 2), (3, 4), (1, 2), (1, 3)]\n",
            "failed tokenization qid: (30299430, 1)\n",
            "Failed line: \n",
            "Failed code line:     print(\"Invalid input. No matching team.\")\n",
            "failed tokenization qid: (37650444, 1)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (10707206, 2)\n",
            "Failed line: \n",
            "Failed code line:     print RunFPing(\"fping -C 1 -q 192.168.1.25\")\n",
            "failed tokenization qid: (32099871, 1)\n",
            "Failed line: \n",
            "Failed code line: print(sorted(names.intersection(substrings(s)))\n",
            "failed tokenization qid: (35997758, 1)\n",
            "Failed line: \n",
            "Failed code line: result = sorted(result, key=itemgetter(1), reverse=True)))\n",
            "failed tokenization qid: (31921226, 2)\n",
            "Failed line: \n",
            "Failed code line:         print match.group(0)\n",
            "failed tokenization qid: (24310571, 0)\n",
            "Failed line: \n",
            "Failed code line:                                           p.components_ / len(x)) + p.mean_)\n",
            "failed tokenization qid: (23254700, 5)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (21285931, 0)\n",
            "Failed line: \n",
            "Failed code line:  'test_data/new_directory': ['ok.txt']})\n",
            "failed tokenization qid: (17144889, 0)\n",
            "Failed line: \n",
            "Failed code line:        all(p_ch==s_ch or p_ch==\"#\" for p_ch, s_ch in zip(problem, solution)\n",
            "failed tokenization qid: (34185590, 2)\n",
            "Failed line: \n",
            "Failed code line:     url(r'^category/(?P<slug>[\\w-]+)/$', 'PrizeType_Index', name=\"prizetype\"),\n",
            "failed tokenization qid: (26836113, 1)\n",
            "Failed line: \n",
            "Failed code line:     do_something(m)\n",
            "failed tokenization qid: (32827687, 1)\n",
            "Failed line: \n",
            "Failed code line: FutureWarning: numpy equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
            "failed tokenization qid: (27207088, 0)\n",
            "Failed line: \n",
            "Failed code line:     some_method(route, handler, **kwargs)\n",
            "failed tokenization qid: (17967426, 0)\n",
            "Failed line: \n",
            "Failed code line:     json.dump(pairs, f)\n",
            "failed tokenization qid: (19385731, 2)\n",
            "Failed line: \n",
            "Failed code line:         return queryset.filter(id=id).get()\n",
            "failed tokenization qid: (29545547, 4)\n",
            "Failed line: \n",
            "Failed code line:         [...]\n",
            "failed tokenization qid: (25677721, 0)\n",
            "Failed line: \n",
            "Failed code line:                                          body=body).execute(num_retries=5)\n",
            "failed tokenization qid: (36673456, 0)\n",
            "39000\n",
            "Failed line: \n",
            "Failed code line: end\n",
            "failed tokenization qid: (28080071, 3)\n",
            "Failed line: \n",
            "Failed code line:     lines.append('\\t'.join(parts))\n",
            "failed tokenization qid: (35919492, 2)\n",
            "Failed line: \n",
            "Failed code line: Risn\n",
            "failed tokenization qid: (13793973, 1)\n",
            "Failed line: \n",
            "Failed code line: file = list(filter(lambda s: s not in st or not s.startswith(t),st.lower().split())\n",
            "failed tokenization qid: (32970204, 6)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (29110968, 1)\n",
            "Failed line: \n",
            "Failed code line: text = ''.join((c for c in str(div) if ord(c) < 128)\n",
            "failed tokenization qid: (33263669, 0)\n",
            "Failed line: \n",
            "Failed code line: The tumor suppressor, PTEN, is a critical negative regulator of Akt activation by PI3-K. Myers et al.\n",
            "failed tokenization qid: (16719294, 0)\n",
            "Failed line: \n",
            "Failed code line:     tbl.setItem(inx,0,QTableWidgetItem(str(row[0]))\n",
            "failed tokenization qid: (34258650, 1)\n",
            "Failed line: \n",
            "Failed code line: re.findall(p, test_str)\n",
            "failed tokenization qid: (27295807, 0)\n",
            "Failed line: \n",
            "Failed code line: print proc.communicate(t\\n)[0]\n",
            "failed tokenization qid: (13512486, 0)\n",
            "Failed line: \n",
            "Failed code line: print [item.lower() for item in row[1::-1] # Same thing, but it helps to break these things up into steps\n",
            "failed tokenization qid: (8441675, 2)\n",
            "Failed line: \n",
            "Failed code line:  (0, 0, 0, 0, 0, 0, 0, 1),\n",
            "failed tokenization qid: (15538354, 0)\n",
            "Failed line: \n",
            "Failed code line:             writer.writerow( (a, ' '.join(map(lambda s:s.decode('utf-8'),b)))\n",
            "failed tokenization qid: (34557821, 0)\n",
            "Failed line: \n",
            "Failed code line: matrix = scipy.sparse.coo_matrix((vs, (ii, jj))\n",
            "failed tokenization qid: (37524151, 1)\n",
            "Failed line: \n",
            "Failed code line:             f.write(\"\\n\".join([s.split(\".\")[0] for s in v])+\"\\n\"\n",
            "failed tokenization qid: (28940185, 3)\n",
            "Failed line: \n",
            "Failed code line:     dic[x].append(i)\n",
            "failed tokenization qid: (14399005, 1)\n",
            "Failed line: \n",
            "Failed code line:     return resdict\n",
            "failed tokenization qid: (32960303, 0)\n",
            "Failed line: \n",
            "Failed code line: [(K[w - weight][0] + value, K[w - weight][1] + [(value, weight)])\n",
            "failed tokenization qid: (27585924, 2)\n",
            "Failed line: \n",
            "Failed code line:     map(lambda x: setattr(x, 'status', prize), group)\n",
            "failed tokenization qid: (2538096, 1)\n",
            "Failed line: \n",
            "Failed code line: my_list.sort()\n",
            "failed tokenization qid: (27049159, 2)\n",
            "40000\n",
            "Failed line: \n",
            "Failed code line: length = len(var_text) # the log and exp cancel!\n",
            "failed tokenization qid: (3654706, 3)\n",
            "Failed line: \n",
            "Failed code line:     setattr(subprocess.Popen, '__call__', real_popen)\n",
            "failed tokenization qid: (5166851, 0)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (32805080, 0)\n",
            "Failed line: \n",
            "Failed code line: ...\n",
            "failed tokenization qid: (13058130, 1)\n",
            "Failed line: \n",
            "Failed code line:     parking = {(lat, long): park for lat, long, park in reader}\n",
            "failed tokenization qid: (23844653, 0)\n",
            "Failed line: \n",
            "Failed code line: {: #lorem_section }\n",
            "failed tokenization qid: (28563230, 2)\n",
            "Failed line: \n",
            "Failed code line: print('\\n'.join(str(int(i)*2) if i.isdigit() else i for i in wordList)\n",
            "failed tokenization qid: (18819012, 1)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (37118464, 1)\n",
            "Failed line: \n",
            "Failed code line: ''.join(filter(lambda x: ord(x)<128,s)\n",
            "failed tokenization qid: (14401232, 1)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (4878369, 1)\n",
            "41000\n",
            "Failed line: \n",
            "Failed code line: dtype: timedelta64[ns]\n",
            "failed tokenization qid: (18389189, 0)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (36163794, 2)\n",
            "Failed line: \n",
            "Failed code line:     <tr class=\"{{ row.tr_class }}\">  <!-- CLASS FOR EACH ROW -->\n",
            "failed tokenization qid: (9525670, 0)\n",
            "Failed line: \n",
            "Failed code line:     my_dict={k:v for k,v in (x.strip().split(':') for x in fd)}\n",
            "failed tokenization qid: (16376888, 1)\n",
            "Failed line: \n",
            "Failed code line:     radios.append(radio)\n",
            "failed tokenization qid: (36044469, 1)\n",
            "Failed line: \n",
            "Failed code line:    Item  other\n",
            "failed tokenization qid: (37358484, 1)\n",
            "Failed line: \n",
            "Failed code line:     b  4\n",
            "failed tokenization qid: (37168829, 0)\n",
            "Failed line: \n",
            "Failed code line: [0.0, 0.968792, 1.0], [1.0], [0.904219, 1.0], [0.920049, 1.0], [0.738674, 0.760266, 1.0]]\n",
            "failed tokenization qid: (30990375, 1)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (19297011, 3)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (14431118, 0)\n",
            "Failed line: \n",
            "Failed code line:         return UserProfile.objects.get_or_create(user=self)[0].get_company())\n",
            "failed tokenization qid: (8084199, 0)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (36393790, 0)\n",
            "Failed line: \n",
            "Failed code line:                                  args[1].lstrip(\" \")[0:args[1].find(')')]\n",
            "failed tokenization qid: (2189259, 0)\n",
            "Failed line: \n",
            "Failed code line:     all_student_scores.append(score)\n",
            "failed tokenization qid: (30432332, 1)\n",
            "42000\n",
            "Failed line: \n",
            "Failed code line:                 break\n",
            "failed tokenization qid: (11890467, 1)\n",
            "Failed line: \n",
            "Failed code line:           d[ch] = 1\n",
            "Failed line: \n",
            "Failed code line:       print('d is now: {}'.format(d))\n",
            "failed tokenization qid: (10274033, 0)\n",
            "Failed line: \n",
            "Failed code line:                             count = 0\n",
            "failed tokenization qid: (27367538, 0)\n",
            "Failed line: \n",
            "Failed code line:  view = View()\n",
            "failed tokenization qid: (4847500, 0)\n",
            "Failed line: \n",
            "Failed code line:         dftemp.to_csv(finalnormCSVFile, mode='a', header=False)\n",
            "failed tokenization qid: (29271257, 0)\n",
            "Failed line: \n",
            "Failed code line: maxel = tuple(max(imap(len,islice(li,st,None,nc)))+2\n",
            "failed tokenization qid: (13655116, 8)\n",
            "Failed line: \n",
            "Failed code line:     # ...\n",
            "failed tokenization qid: (33200477, 2)\n",
            "Failed line: \n",
            "Failed code line:        return func(*args, **kwargs)\n",
            "failed tokenization qid: (12256220, 1)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (27194585, 2)\n",
            "Failed line: \n",
            "Failed code line: g.vs(**{'{}_lt'.format(atr): c}\n",
            "failed tokenization qid: (31192009, 0)\n",
            "Failed line: \n",
            "Failed code line:         self.fields['from_company'].queryset = Contact.object.filter(...\n",
            "failed tokenization qid: (488036, 0)\n",
            "Failed line: \n",
            "Failed code line:    [3, 4, 5]])\n",
            "failed tokenization qid: (34123122, 0)\n",
            "Failed line: \n",
            "Failed code line:                        0         1         2         3         4         5\n",
            "failed tokenization qid: (36829287, 0)\n",
            "Failed line: \n",
            "Failed code line: 4.75\n",
            "failed tokenization qid: (27974208, 1)\n",
            "Failed line: \n",
            "Failed code line:     arr[tup][mask1]=i+1\n",
            "failed tokenization qid: (36178631, 0)\n",
            "Failed line: \n",
            "Failed code line:         count2 += 1\n",
            "Failed line: \n",
            "Failed code line:           continue\n",
            "failed tokenization qid: (25921372, 0)\n",
            "Failed line: \n",
            "Failed code line:         nodes[e[\"PARENT\"]].add_children(nodes[e[\"NAME\"])\n",
            "failed tokenization qid: (16204230, 0)\n",
            "Failed line: \n",
            "Failed code line: key:\\s*'?([^'\\n]*)'?\n",
            "failed tokenization qid: (25778620, 0)\n",
            "43000\n",
            "Failed line: \n",
            "Failed code line: return base_qs.values(# as above\n",
            "failed tokenization qid: (25004865, 1)\n",
            "Failed line: \n",
            "Failed code line: 5         (POLYGON ((970217.0223999023437500 145643.3322...\n",
            "failed tokenization qid: (17748913, 1)\n",
            "Failed line: \n",
            "Failed code line:         filename = \"/index.htm\"\n",
            "failed tokenization qid: (30959649, 1)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (21405036, 1)\n",
            "Failed line: \n",
            "Failed code line:             e.g. `['%.3e + %.3ej', '(%.15e%+.15ej)']` for 2 columns\n",
            "failed tokenization qid: (21114265, 0)\n",
            "Failed line: \n",
            "Failed code line: listbox.insert(END, ' '.join([i]+dic[i])\n",
            "failed tokenization qid: (11427363, 0)\n",
            "Failed line: \n",
            "Failed code line: method()\n",
            "failed tokenization qid: (7936572, 0)\n",
            "Failed line: \n",
            "Failed code line:     return ' '.join([ '-'.join(map(str, range)) for range in new_ranges ]\n",
            "failed tokenization qid: (34448005, 0)\n",
            "Failed line: \n",
            "Failed code line:                     results.append(m_new)\n",
            "failed tokenization qid: (817284, 1)\n",
            "44000\n",
            "Failed line: \n",
            "Failed code line: ['id2,30,400,1', 'id1,100,200,0']\n",
            "failed tokenization qid: (36439536, 0)\n",
            "Failed line: \n",
            "Failed code line: directory.sort( key=lambda x: x.lstrip(\"_\")))\n",
            "failed tokenization qid: (31418085, 1)\n",
            "Failed line: \n",
            "Failed code line: res.index, res.columns = df_index[::2], df_cols[::2]\n",
            "failed tokenization qid: (18825412, 4)\n",
            "Failed line: \n",
            "Failed code line:   result = [result.get() for result in results_objects]\n",
            "failed tokenization qid: (27391132, 0)\n",
            "Failed line: \n",
            "Failed code line:                       for student_answers in all_student_answers]\n",
            "failed tokenization qid: (30432332, 2)\n",
            "Failed line: \n",
            "Failed code line: {% endblock common_name %}\n",
            "failed tokenization qid: (17562664, 1)\n",
            "Failed line: \n",
            "Failed code line:             i, k, A_dict[k], value[1], value[2], value[3])\n",
            "failed tokenization qid: (7225073, 2)\n",
            "Failed line: \n",
            "Failed code line:                                        1                                        \n",
            "Failed line: \n",
            "Failed code line:                                       1 1                                       \n",
            "Failed line: \n",
            "Failed code line:                                      1 2 1                                      \n",
            "Failed line: \n",
            "Failed code line:                                     1 3 3 1                                     \n",
            "Failed line: \n",
            "Failed code line:                                    1 4 6 4 1                                    \n",
            "failed tokenization qid: (9612531, 1)\n",
            "Failed line: \n",
            "Failed code line: Name: File, dtype: object\n",
            "failed tokenization qid: (21296571, 0)\n",
            "Failed line: \n",
            "Failed code line:     ...\n",
            "failed tokenization qid: (34626470, 1)\n",
            "45000\n",
            "Failed line: \n",
            "Failed code line:             print(\"unable to parse line %d: %s\" % (line_num, line)\n",
            "failed tokenization qid: (10069689, 1)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (20189051, 0)\n",
            "Failed line: \n",
            "Failed code line:                             not (line.startswith(\"c\") or line.startswith(\"p\"))]\n",
            "failed tokenization qid: (14254595, 0)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (5446372, 2)\n",
            "Failed line: \n",
            "Failed code line: pkts = sniff(filter=\"udp and port 5060\", count=0, store=0, prn=insert_into_mysql)\n",
            "failed tokenization qid: (22954300, 0)\n",
            "Failed line: \n",
            "Failed code line:         byte |= value\n",
            "failed tokenization qid: (34496234, 0)\n",
            "Failed line: \n",
            "Failed code line: print \"Tu palabra: {}\".format(bifid(data))\n",
            "failed tokenization qid: (29485408, 0)\n",
            "Failed line: \n",
            "Failed code line: filepath = str(QFileDialog.getOpenFileName(options=QFileDialog.DontUseNativeDialog)))\n",
            "failed tokenization qid: (11479109, 1)\n",
            "Failed line: \n",
            "Failed code line: oApp = None\n",
            "failed tokenization qid: (36112512, 1)\n",
            "Failed line: \n",
            "Failed code line:               9 POP_TOP\n",
            "failed tokenization qid: (36471083, 0)\n",
            "Failed line: \n",
            "Failed code line:                  if k in other or (self.pop(k, 0) and False})\n",
            "failed tokenization qid: (32555183, 0)\n",
            "Failed line: \n",
            "Failed code line:         print \",\".join(str(dic[y.strip()]) for y in x)\n",
            "failed tokenization qid: (13412248, 1)\n",
            "Failed line: \n",
            "Failed code line:    mapValues(lambda vals: [x for (x, i) in sorted(vals, key=lambda (x, i): i)])))\n",
            "failed tokenization qid: (31597151, 0)\n",
            "Failed line: \n",
            "Failed code line:     # do stuff with your tuples of longs and lats for each user_id\n",
            "failed tokenization qid: (30528044, 0)\n",
            "Failed line: \n",
            "Failed code line:      result =  ...\n",
            "failed tokenization qid: (28115449, 1)\n",
            "Failed line: \n",
            "Failed code line:     arrays.append(np.array((array.float(i) for i in l)))\n",
            "failed tokenization qid: (6213336, 1)\n",
            "46000\n",
            "Failed line: \n",
            "Failed code line:               0   1   2     3   4              5\n",
            "Failed line: \n",
            "Failed code line:           Time  H1  N2 Time_1 N2_1 Time Relative\n",
            "Failed line: \n",
            "Failed code line:           Time  H1 Time Relative\n",
            "failed tokenization qid: (14984119, 3)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (20189051, 1)\n",
            "Failed line: \n",
            "Failed code line: re.findall('\".+?\"', # or '\"[^\"]+\"', input)\n",
            "failed tokenization qid: (16603310, 0)\n",
            "Failed line: \n",
            "Failed code line:                   6  2007-12-31\n",
            "failed tokenization qid: (24099630, 1)\n",
            "Failed line: \n",
            "Failed code line: matches = [s for s in strings if any(f in s for f in filters))]\n",
            "failed tokenization qid: (32827687, 0)\n",
            "Failed line: \n",
            "Failed code line:             print(type(results))\n",
            "Failed line: \n",
            "Failed code line:                 print(type(results))\n",
            "Failed line: \n",
            "Failed code line:                      pass\n",
            "Failed line: \n",
            "Failed code line:             list(results)\n",
            "failed tokenization qid: (35089127, 0)\n",
            "Failed line: \n",
            "Failed code line: {'A{}'.format(next(index)): v for v in sorted(os.listdir(\"T:\\\\\") if certain_condition(v)}\n",
            "failed tokenization qid: (22301693, 2)\n",
            "Failed line: \n",
            "Failed code line:                 revdict[gid].append(seqid)\n",
            "failed tokenization qid: (25001793, 1)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (13955651, 4)\n",
            "Failed line: \n",
            "Failed code line: best_match = min(slices(string_), key=functools.partial(diff, target_string))\n",
            "failed tokenization qid: (4203142, 1)\n",
            "Failed line: \n",
            "Failed code line:               out.write(\"print _(%s)\\n\" % (repr(row[0],))\n",
            "failed tokenization qid: (14201517, 0)\n",
            "Failed line: \n",
            "Failed code line: \\[[^]]+\\]\\([^\\)]+\\)\n",
            "failed tokenization qid: (33111484, 0)\n",
            "Failed line: \n",
            "Failed code line: #options = [( c.strftime(\"%H:%M:%S\"), c.strftime(\"%I:%M %p\")) for c in times]\n",
            "failed tokenization qid: (35964952, 1)\n",
            "47000\n",
            "Failed line: \n",
            "Failed code line: bob = [item for sublist in l for item in sublist\n",
            "failed tokenization qid: (25714701, 0)\n",
            "Failed line: \n",
            "Failed code line:     tags.extend([e.strip(\"'():,&;+?][ \") for e in item if e not in remove]\n",
            "failed tokenization qid: (27011647, 1)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (28279732, 2)\n",
            "Failed line: \n",
            "Failed code line:           }\n",
            "failed tokenization qid: (30858338, 1)\n",
            "Failed line: \n",
            "Failed code line:         print(\", \".join(data))\n",
            "failed tokenization qid: (31946018, 0)\n",
            "Failed line: \n",
            "Failed code line: print('\\n'.join(fList[:20])\n",
            "failed tokenization qid: (15176190, 1)\n",
            "Failed line: \n",
            "Failed code line:     print(line.replace('width=.5\\\\textwidth', 'width=.9\\\\textwidth'), end=' ')))\n",
            "failed tokenization qid: (33858336, 1)\n",
            "Failed line: \n",
            "Failed code line:     rename(file_name, path.join(pth, path.basename(file_name).split(\"_\",1)[1])\n",
            "failed tokenization qid: (34243896, 0)\n",
            "Failed line: \n",
            "Failed code line:    return json.dumps(new_cars)\n",
            "failed tokenization qid: (13653334, 0)\n",
            "Failed line: \n",
            "Failed code line: # </root>\n",
            "failed tokenization qid: (127606, 4)\n",
            "Failed line: \n",
            "Failed code line: a = a[:, 3000:]\n",
            "failed tokenization qid: (14078818, 0)\n",
            "Failed line: \n",
            "Failed code line:     col = df.apply(lambda row,col=col,day=day: annualize_spend(col,day,row), axis = 1)\n",
            "failed tokenization qid: (33312319, 3)\n",
            "48000\n",
            "Failed line: \n",
            "Failed code line:             return quickSelect(smallerList,k)\n",
            "failed tokenization qid: (22184676, 0)\n",
            "Failed line: \n",
            "Failed code line: 2  5  0  1  2  3  4  5  6  7  8 ...  40  41  42  43  44  45  46  47  48  49\n",
            "failed tokenization qid: (36881326, 0)\n",
            "Failed line: \n",
            "Failed code line: ...\n",
            "failed tokenization qid: (28258813, 0)\n",
            "Failed line: \n",
            "Failed code line: print(\"\".join(x for x in name if x.isdigit())\n",
            "failed tokenization qid: (28952756, 2)\n",
            "Failed line: \n",
            "Failed code line:   ....\n",
            "failed tokenization qid: (28678487, 3)\n",
            "Failed line: \n",
            "Failed code line:                 for i in range(len(order)-1)))\n",
            "failed tokenization qid: (14300603, 0)\n",
            "Failed line: \n",
            "Failed code line:     print('\\n'.join(str(float(i)*2) if i.isdigit() else i for i in wordList)\n",
            "failed tokenization qid: (18819012, 2)\n",
            "Failed line: \n",
            "Failed code line:                                          sortByLanguages(possibleLanguages))\n",
            "failed tokenization qid: (19622827, 1)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (26857515, 1)\n",
            "Failed line: \n",
            "Failed code line:     (len(n) - len(n.translate(None, \"\\t\")))\n",
            "failed tokenization qid: (29922108, 1)\n",
            "Failed line: \n",
            "Failed code line:              if line[3] != '']\n",
            "failed tokenization qid: (12591850, 1)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (29257716, 4)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (11125878, 0)\n",
            "49000\n",
            "Failed line: \n",
            "Failed code line:         writer.writerow(row + [field, court])\n",
            "failed tokenization qid: (19312524, 3)\n",
            "Failed line: \n",
            "Failed code line: print '{}:{}\\n {}:{}\\n {}:{}'.format('red', color_times['red'], 'blue', color_times['blue', 'green', color_times['green'])\n",
            "failed tokenization qid: (15983740, 0)\n",
            "Failed line: \n",
            "Failed code line:     }\n",
            "failed tokenization qid: (32498607, 0)\n",
            "Failed line: \n",
            "Failed code line:         pass\n",
            "failed tokenization qid: (21641023, 2)\n",
            "Failed line: \n",
            "Failed code line:     else:ans.append(x)\n",
            "failed tokenization qid: (13900106, 1)\n",
            "Failed line: \n",
            "Failed code line:        *\n",
            "Failed line: \n",
            "Failed code line:       ***\n",
            "Failed line: \n",
            "Failed code line:        *\n",
            "Failed line: \n",
            "Failed code line:       ***\n",
            "failed tokenization qid: (33136354, 1)\n",
            "Failed line: \n",
            "Failed code line:     yield 'Chunk 5\\n'\n",
            "failed tokenization qid: (940816, 1)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (14709244, 2)\n",
            "Failed line: \n",
            "Failed code line:     return(data)\n",
            "failed tokenization qid: (18631014, 1)\n",
            "Failed line: \n",
            "Failed code line:    print(str(item + \"|\" + strs + \"\\n\" + (\"-------------\" * 7)))\n",
            "failed tokenization qid: (17283144, 1)\n",
            "Failed line: \n",
            "Failed code line:         print title_list.css('li::text').extract()\n",
            "failed tokenization qid: (31779226, 0)\n",
            "Failed line: \n",
            "Failed code line:            pass\n",
            "failed tokenization qid: (11609088, 1)\n",
            "Failed line: \n",
            "Failed code line: ['e', 'b', 'a'] => [5}]\n",
            "failed tokenization qid: (18178504, 1)\n",
            "Failed line: \n",
            "Failed code line:             print(\"Student {}: {}\".format(k, getattr(get, k)))\n",
            "failed tokenization qid: (31089612, 6)\n",
            "Failed line: \n",
            "Failed code line:             pass\n",
            "failed tokenization qid: (22554125, 1)\n",
            "Failed line: \n",
            "Failed code line: mylist[:] = [s for s in mylist if not re.search(r\"\\bis the colour\\b\",s)])\n",
            "failed tokenization qid: (32057959, 0)\n",
            "Failed line: \n",
            "Failed code line:                        |\n",
            "Failed line: \n",
            "Failed code line:                           |\n",
            "failed tokenization qid: (29190982, 2)\n",
            "Failed line: \n",
            "Failed code line:         print \",\".join(map(str,x))\n",
            "failed tokenization qid: (13412248, 0)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (25594825, 3)\n",
            "Failed line: \n",
            "Failed code line:     return items\n",
            "failed tokenization qid: (34294340, 1)\n",
            "Failed line: \n",
            "Failed code line:     return super(ListAllObjectsManager, self).get_queryset().filter(**param_filter))\n",
            "failed tokenization qid: (23783100, 0)\n",
            "Failed line: \n",
            "Failed code line: handler(*args)\n",
            "failed tokenization qid: (20881418, 0)\n",
            "50000\n",
            "Failed line: \n",
            "Failed code line:          code = str(input('Type hier uw code in die u wilt controleren:\\n'))\n",
            "Failed line: \n",
            "Failed code line:             print('code komt overheen, en wordt nu gecheckt of de aanbieder wel correct is.')\n",
            "failed tokenization qid: (33101320, 1)\n",
            "Failed line: \n",
            "Failed code line:                     if depth < 3:\n",
            "Failed line: \n",
            "Failed code line:             futures.submit(backtraking, new_state, depth + 1)\n",
            "failed tokenization qid: (24914741, 1)\n",
            "Failed line: \n",
            "Failed code line:       sep='\\n')\n",
            "failed tokenization qid: (27336605, 1)\n",
            "Failed line: \n",
            "Failed code line:             if (PyDict_Update(d, kwdict) != 0) {\n",
            "failed tokenization qid: (22365847, 1)\n",
            "Failed line: \n",
            "Failed code line:     print ', '.join(map(str, test[:-1])) + (' and ' if len(test) > 1 else '') + str(test[-1])\n",
            "failed tokenization qid: (31339968, 0)\n",
            "Failed line: \n",
            "Failed code line:                               dev  node meas 0 meas 1\n",
            "failed tokenization qid: (36564142, 0)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (28116558, 3)\n",
            "Failed line: \n",
            "Failed code line: d = {str(row.getValue(\"Column1\")): (str(row.getValue(\"Column{0}\".format(i)) for i in [2, 3, 4]) for i in arcpy.SearchCursor(xls,\"[Column1] = 'Lake_Huron'\")}\n",
            "failed tokenization qid: (22410018, 1)\n",
            "Failed line: \n",
            "Failed code line:    or re.search(r'[^A-Za-z0-9_\\-\\\\]',userpath):\n",
            "failed tokenization qid: (8686880, 2)\n",
            "Failed line: \n",
            "Failed code line:     def __del__(...\n",
            "failed tokenization qid: (10436516, 0)\n",
            "Failed line: \n",
            "Failed code line:     raise ValueError(\"data file contents are not in a valid format\")\n",
            "failed tokenization qid: (6311738, 1)\n",
            "Failed line: \n",
            "Failed code line:  $('input[name=A][value=\"' + str+ '\"]').prop('checked', false);\n",
            "failed tokenization qid: (28538931, 1)\n",
            "Failed line: \n",
            "Failed code line: soup.find_all(\"a\", id=lambda value: value and value.startswith(\"link\"))  # id starts with 'link'\n",
            "failed tokenization qid: (33508202, 0)\n",
            "Failed line: \n",
            "Failed code line:       return instance\n",
            "failed tokenization qid: (32000147, 0)\n",
            "51000\n",
            "Failed line: \n",
            "Failed code line: [(1, 2, 3), (4, 5, 6), (7, 8, 9)]\n",
            "failed tokenization qid: (24007070, 0)\n",
            "Failed line: \n",
            "Failed code line:         filename = \"index.htm\"\n",
            "failed tokenization qid: (30959649, 0)\n",
            "Failed line: \n",
            "Failed code line: \"[^\"\\\\]*(?:\\\\.[^\"\\\\]*)*\"\n",
            "failed tokenization qid: (37378156, 1)\n",
            "Failed line: \n",
            "Failed code line:             BIOSdict[\"SoftwareElementID\"] = str((v['data']['BIOS Revision'])\n",
            "failed tokenization qid: (13814428, 0)\n",
            "Failed line: \n",
            "Failed code line:         do_something_with(row['Twitter handle']\n",
            "failed tokenization qid: (19507425, 0)\n",
            "Failed line: \n",
            "Failed code line:                 print 'incorrect version'\n",
            "failed tokenization qid: (9158666, 1)\n",
            "Failed line: \n",
            "Failed code line: print(list)\n",
            "failed tokenization qid: (31422956, 1)\n",
            "Failed line: \n",
            "Failed code line:          1    1   2\n",
            "Failed line: \n",
            "Failed code line:       2  1    2   1\n",
            "failed tokenization qid: (22521414, 0)\n",
            "Failed line: \n",
            "Failed code line:         print i1, i2, l[i1][i2]\n",
            "failed tokenization qid: (8189169, 0)\n",
            "Failed line: \n",
            "Failed code line:     os.remove(file.name)\n",
            "failed tokenization qid: (15343447, 2)\n",
            "Failed line: \n",
            "Failed code line:         listA.append(line)\n",
            "failed tokenization qid: (20439210, 0)\n",
            "Failed line: \n",
            "Failed code line: self.submit_button = Tkinter.Button(self.parent, text = \"Insert\", command = self.insert_data\n",
            "failed tokenization qid: (36120426, 1)\n",
            "Failed line: \n",
            "Failed code line:         output_file.writelines([part for part in line if part.startswith('Mon-')][0] + '\\n' for line in reader])\n",
            "failed tokenization qid: (20253203, 2)\n",
            "Failed line: \n",
            "Failed code line: dtype: object\n",
            "failed tokenization qid: (29501102, 0)\n",
            "Failed line: \n",
            "Failed code line: [\"Here's\", 'sentence:']\n",
            "failed tokenization qid: (2270634, 2)\n",
            "52000\n",
            "Failed line: \n",
            "Failed code line: OkButton = tkinter.Button(root, text = \"Ok\", command = lambda: OkClicked(textbox1)\n",
            "failed tokenization qid: (30274896, 0)\n",
            "Failed line: \n",
            "Failed code line: </ul>\n",
            "failed tokenization qid: (19335369, 0)\n",
            "Failed line: \n",
            "Failed code line:         # Looping over each visit's immunizations\n",
            "Failed line: \n",
            "Failed code line:             visitimm.append((i, duedate))\n",
            "failed tokenization qid: (18188403, 2)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (34514768, 0)\n",
            "Failed line: \n",
            "Failed code line:     d[name].extend(map(int,scores.split()))\n",
            "failed tokenization qid: (28347660, 0)\n",
            "Failed line: \n",
            "Failed code line:         t = time.strptime(date,'%m%d%Y')\n",
            "failed tokenization qid: (36322594, 4)\n",
            "Failed line: \n",
            "Failed code line:     counter += (len(a) - len(b))\n",
            "failed tokenization qid: (30442623, 1)\n",
            "Failed line: \n",
            "Failed code line:        b.Bind(wx.EVT_BUTTON, self.OnClick)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (34503531, 1)\n",
            "Failed line: \n",
            "Failed code line: [('a', 'A'), ('B', 'b'), (None, 'C')]\n",
            "failed tokenization qid: (29502527, 0)\n",
            "Failed line: \n",
            "Failed code line:             data[next(cn)] = d\n",
            "failed tokenization qid: (32852006, 6)\n",
            "Failed line: \n",
            "Failed code line:                 i, k, v, value[1], value[2], value[3])\n",
            "failed tokenization qid: (7225073, 1)\n",
            "Failed line: \n",
            "Failed code line: result = map(''.join, initial)\n",
            "failed tokenization qid: (17379035, 0)\n",
            "Failed line: \n",
            "Failed code line:         self.log('%s %s\\n' % (except_str, str(e)))\n",
            "failed tokenization qid: (19363527, 2)\n",
            "Failed line: \n",
            "Failed code line:      '''replace all characters in a string with a different character'''\n",
            "failed tokenization qid: (17829875, 1)\n",
            "Failed line: \n",
            "Failed code line:     return map(get_nth_func, range(count)\n",
            "failed tokenization qid: (13519618, 0)\n",
            "Failed line: \n",
            "Failed code line: t;').replace('>', '&gt;').replace('\"', '&quot;').replace(\"'\", '&#39;'))\n",
            "failed tokenization qid: (275174, 0)\n",
            "Failed line: \n",
            "Failed code line:         return locale.format(\"%d\", value, grouping=True) ##New Line\n",
            "failed tokenization qid: (12905651, 0)\n",
            "Failed line: \n",
            "Failed code line:         return default\n",
            "failed tokenization qid: (12451531, 2)\n",
            "Failed line: \n",
            "Failed code line: matrix = vect.fit_transform(traindata)\n",
            "failed tokenization qid: (19753945, 2)\n",
            "53000\n",
            "Failed line: \n",
            "Failed code line: soup.find('div', {\"class\": lambda x: x and x.startswith(\"divnew\"))})\n",
            "failed tokenization qid: (31004430, 1)\n",
            "Failed line: \n",
            "Failed code line: reduce(lambda x, y: x | y, [Q(name__contains=word) for word in list]))\n",
            "failed tokenization qid: (7088173, 1)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (28635986, 1)\n",
            "Failed line: \n",
            "Failed code line: [233.0, 233.0, 233.0, 233.0]\n",
            "failed tokenization qid: (37313871, 0)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (32381582, 0)\n",
            "Failed line: \n",
            "Failed code line: (26 34)\n",
            "failed tokenization qid: (21436677, 0)\n",
            "Failed line: \n",
            "Failed code line:     cv::cvtColor(input, grayscale, cv::COLOR_BGR2GRAY);\n",
            "failed tokenization qid: (19966423, 0)\n",
            "Failed line: \n",
            "Failed code line: D 2014-07-08 2014-07-09 2014-07-10\n",
            "failed tokenization qid: (34676142, 0)\n",
            "Failed line: \n",
            "Failed code line:  ('diamond', 1), ('diamond', 2), ('diamond', 3), ('diamond', 4), ('diamond', 5), ('diamond', 6), ('diamond', 7), ('diamond', 8), ('diamond', 9), ('diamond', 10)]\n",
            "failed tokenization qid: (24407586, 1)\n",
            "Failed line: \n",
            "Failed code line:               [ 0, 0, 0, 1])\n",
            "failed tokenization qid: (22175385, 0)\n",
            "Failed line: \n",
            "Failed code line: df_masked = df[mask]\n",
            "failed tokenization qid: (16341367, 0)\n",
            "Failed line: \n",
            "Failed code line: outdata.to_csv('out.csv', header=False, index=False)\n",
            "failed tokenization qid: (25838335, 1)\n",
            "Failed line: \n",
            "Failed code line: combined = xr.concat(patient_list, dim=pd.Index(patients, name='patient')\n",
            "failed tokenization qid: (36948476, 3)\n",
            "Failed line: \n",
            "Failed code line:      function1()\n",
            "failed tokenization qid: (34873156, 1)\n",
            "Failed line: \n",
            "Failed code line: arrays = [make_array(row) for row in parser]\n",
            "failed tokenization qid: (6213336, 2)\n",
            "Failed line: \n",
            "Failed code line:       return\n",
            "failed tokenization qid: (8365714, 1)\n",
            "Failed line: \n",
            "Failed code line:          Time  H1  N2  Time.1  N2.1  Time Relative\n",
            "Failed line: \n",
            "Failed code line:              Time  H1  Time Relative\n",
            "failed tokenization qid: (14984119, 2)\n",
            "54000\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (27429617, 1)\n",
            "Failed line: \n",
            "Failed code line: print V(theta,N)\n",
            "failed tokenization qid: (12167660, 0)\n",
            "Failed line: \n",
            "Failed code line: In [86]: [elt.text_content() for elt in doc.xpath('//div[@id=\"my-players-table\"]/div//table/tr/td')]\n",
            "failed tokenization qid: (27647973, 4)\n",
            "Failed line: \n",
            "Failed code line:     raise IndexError('{} not found in the list'.format(Cheese(1))\n",
            "failed tokenization qid: (21963573, 1)\n",
            "Failed line: \n",
            "Failed code line: 1 loops, best of 3: 30.7 s per loop\n",
            "failed tokenization qid: (35622837, 2)\n",
            "Failed line: \n",
            "Failed code line:     category = SelectQueryField(query=Category.filter(some_val=other_val)\n",
            "failed tokenization qid: (9628271, 0)\n",
            "Failed line: \n",
            "Failed code line: main(#REPLACE_THIS#)\n",
            "failed tokenization qid: (21100203, 0)\n",
            "Failed line: \n",
            "Failed code line: bin= list( chain( *[\"{0:b}\".format(ord(c)) for c in message] )\n",
            "failed tokenization qid: (33985791, 4)\n",
            "55000\n",
            "Failed line: \n",
            "Failed code line: np.asarray([[[x1,x2,x3...],[y1,y2,y3...]]) == np.asarray([(x1,y1),(x2,y2),(x3,y3)...]).T\n",
            "failed tokenization qid: (29504382, 1)\n",
            "Failed line: \n",
            "Failed code line:     tags.extend([e.strip(\"'():,&;+?][ \") for e in item if e not in remove]\n",
            "failed tokenization qid: (27011647, 0)\n",
            "Failed line: \n",
            "Failed code line:     F[tup]=[tup[0],np.nan,tup[1]]\n",
            "failed tokenization qid: (29466015, 1)\n",
            "Failed line: \n",
            "Failed code line:      print(fileinput.filename(), fileinput.filelineno(), line)\n",
            "failed tokenization qid: (21731097, 0)\n",
            "Failed line: \n",
            "Failed code line: item_lines = '\\n'.join(str(x) for x in enumerate(['red', 'orange', 'yellow', 'green'], 1)))\n",
            "failed tokenization qid: (7439513, 2)\n",
            "Failed line: \n",
            "Failed code line:               9 LOAD_FAST                1 (c_string)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (32179653, 0)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (33837755, 0)\n",
            "Failed line: \n",
            "Failed code line:     self.__dict__[stat] = parser.get(self.char_class, stat))\n",
            "failed tokenization qid: (20747862, 1)\n",
            "Failed line: \n",
            "Failed code line: template = \"\"\"\n",
            "Failed position: 9\n",
            "wordpunct_tokenizer tokenization: \n",
            "['=', '\"\"\"']\n",
            "failed tokenization qid: (25978879, 0)\n",
            "Failed line: \n",
            "Failed code line:     return 'mything('+repr(self._list)[1:-1]+')')\n",
            "failed tokenization qid: (2858921, 0)\n",
            "Failed line: \n",
            "Failed code line:     hand.add((random.randint(2,14), random.randint(0, 3))\n",
            "failed tokenization qid: (29308912, 1)\n",
            "Failed line: \n",
            "Failed code line:        print(line)\n",
            "failed tokenization qid: (28454330, 1)\n",
            "Failed line: \n",
            "Failed code line:      open('C:/Exports/result.csv', 'w') as outfile:\n",
            "failed tokenization qid: (37460683, 0)\n",
            "56000\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (12599972, 0)\n",
            "Failed line: \n",
            "Failed code line:         print x\n",
            "failed tokenization qid: (12874986, 0)\n",
            "Failed line: \n",
            "Failed code line: (STR\\()\"(.+?)(?<!\\\\)(\"\\))\n",
            "failed tokenization qid: (27887545, 0)\n",
            "Failed line: \n",
            "Failed code line: print (\"the smallest number is\", ismallest)\n",
            "failed tokenization qid: (23002473, 1)\n",
            "Failed line: \n",
            "Failed code line:  #Quit\n",
            "failed tokenization qid: (37401372, 0)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (37118464, 0)\n",
            "Failed line: \n",
            "Failed code line:              1.2                 foo\n",
            "failed tokenization qid: (30399119, 3)\n",
            "Failed line: \n",
            "Failed code line:                 Tkinter.Text.__init__(self)\n",
            "Failed line: \n",
            "Failed code line:                  printout.insert(Tkinter.END, message)\n",
            "failed tokenization qid: (25600994, 2)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (13956871, 1)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (22630066, 0)\n",
            "57000\n",
            "Failed line: \n",
            "Failed code line:         .groupby(['Time','Category']).sum().reset_index().sort_values('Category')\n",
            "failed tokenization qid: (36860185, 0)\n",
            "Failed line: \n",
            "Failed code line:     dd[i,i]=1\n",
            "failed tokenization qid: (32408355, 1)\n",
            "Failed line: \n",
            "Failed code line: 2  56   1.5\n",
            "failed tokenization qid: (29785797, 0)\n",
            "Failed line: \n",
            "Failed code line:         raise IntegrityError(\"Error message\")\n",
            "failed tokenization qid: (10576797, 1)\n",
            "Failed line: \n",
            "Failed code line:         print x,'-->',reduce(set.intersection,imap(set,x))\n",
            "failed tokenization qid: (14456201, 2)\n",
            "Failed line: \n",
            "Failed code line: data.loc[data.index[20:], 'Volume Ratio'] = (data.loc[:20:, 'acend'].rolling(window=20).sum() / (data.loc[:20:, 'Volume'].rolling(window=20).sum() - data.loc[:20:, 'acend'].rolling(window=20).sum()) * 100\n",
            "failed tokenization qid: (37523730, 0)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (5178212, 2)\n",
            "58000\n",
            "Failed line: \n",
            "Failed code line:         print(last_message.text)\n",
            "failed tokenization qid: (35390843, 1)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (11168428, 0)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (33267434, 0)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "Failed line: \n",
            "Failed code line: \n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (36998069, 4)\n",
            "Failed line: \n",
            "Failed code line:         users[user]= [ tolu, open(some_directory+user,\"w\"), user ]\n",
            "failed tokenization qid: (4667434, 5)\n",
            "Failed line: \n",
            "Failed code line: dtypes: float64(2)\n",
            "failed tokenization qid: (18491609, 1)\n",
            "Failed line: \n",
            "Failed code line: print re.findall(r\"\\bLayer\\b[\\s\\S]*?(?=\\nLayer\\b|$)\",x\n",
            "failed tokenization qid: (33383307, 2)\n",
            "Failed line: \n",
            "Failed code line:     Al[i]=np.c_[l,newC]\n",
            "failed tokenization qid: (33870862, 1)\n",
            "Failed line: \n",
            "Failed code line: # nDigits can also be caluclated as follows: numDigits = int(math.log(num,10))+1\n",
            "failed tokenization qid: (20252857, 1)\n",
            "Failed line: \n",
            "Failed code line:     return answer\n",
            "failed tokenization qid: (34599378, 1)\n",
            "Failed line: \n",
            "Failed code line: client.SendMessage(user, message)\n",
            "failed tokenization qid: (4536146, 0)\n",
            "Failed line: \n",
            "Failed code line: 0.59134766185007948\n",
            "failed tokenization qid: (16944362, 0)\n",
            "Failed line: \n",
            "Failed code line: logger2.error('The five boxing wizards jump quickly.') # Printed and to file.\n",
            "failed tokenization qid: (22250799, 1)\n",
            "59000\n",
            "Failed line: \n",
            "Failed code line: {% endif %}\n",
            "failed tokenization qid: (2393237, 0)\n",
            "Failed line: \n",
            "Failed code line: lambda t: (t[0][0], t[0][1], t[0][2], ..., t[1]))\n",
            "failed tokenization qid: (32058148, 2)\n",
            "Failed line: \n",
            "Failed code line:    text = \"\\n\".join([\" \".join([ch.upper() if ch == \"i\" else ch for ch in line.split()]) for line in myfi\n",
            "failed tokenization qid: (37082185, 1)\n",
            "Failed line: \n",
            "Failed code line: file_paths = [os.path.join(root, f) for root, _, files in os.walk('.') for f in files if (f != '.DS_Store') or f.endswith('.txt'))]\n",
            "failed tokenization qid: (12571418, 1)\n",
            "Failed line: \n",
            "Failed code line:             files.append((file, newFileName))\n",
            "failed tokenization qid: (25038027, 1)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (17640235, 0)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (34028511, 2)\n",
            "Failed line: \n",
            "Failed code line: [('__doc__', None), ('__init__','<unboound method.....>), etc)]\n",
            "failed tokenization qid: (28821360, 0)\n",
            "Failed line: \n",
            "Failed code line: Out[15]: [(1, 13), (4, 16), (2, 14), (5, 17), (3, 15), (6, 18)]\n",
            "failed tokenization qid: (29710155, 2)\n",
            "60000\n",
            "Failed line: \n",
            "Failed code line:     sub[1] = -2\n",
            "failed tokenization qid: (36282772, 2)\n",
            "Failed line: \n",
            "Failed code line: leftmost = min((pos, sub) for pos, sub in positions if pos > -1)[1]\n",
            "failed tokenization qid: (36765952, 0)\n",
            "Failed line: \n",
            "Failed code line:             print('\\tVolume Status: {}'.format(bd.volume_status))\n",
            "failed tokenization qid: (29497029, 0)\n",
            "Failed line: \n",
            "Failed code line: print(filter(lambda x: isinstance(getattr(B, x), type), b.members)))\n",
            "failed tokenization qid: (23271192, 1)\n",
            "Failed line: \n",
            "Failed code line: ...,\n",
            "failed tokenization qid: (32244565, 1)\n",
            "Failed line: \n",
            "Failed code line:     *     \n",
            "Failed line: \n",
            "Failed code line:    ***    \n",
            "Failed line: \n",
            "Failed code line:   *****   \n",
            "Failed line: \n",
            "Failed code line:   *  \n",
            "failed tokenization qid: (19641162, 0)\n",
            "Failed line: \n",
            "Failed code line: cases = x.findall(\".//testcase[@name='VHDL_BUILD_Passthrough'][@classname='TestOne']\"\n",
            "failed tokenization qid: (4808753, 0)\n",
            "Failed line: \n",
            "Failed code line:     print datetime.strptime('%s %s %s' % (part[0][:-2]), part[1], part[2]), '%d %B %Y').strftime('%Y%m%d')\n",
            "failed tokenization qid: (6941965, 2)\n",
            "Failed line: \n",
            "Failed code line: plt.show()\n",
            "failed tokenization qid: (27027500, 2)\n",
            "Failed line: \n",
            "Failed code line:      *      \n",
            "Failed line: \n",
            "Failed code line:     ***     \n",
            "Failed line: \n",
            "Failed code line:    *****    \n",
            "Failed line: \n",
            "Failed code line:   *******   \n",
            "Failed line: \n",
            "Failed code line:       *       \n",
            "Failed line: \n",
            "Failed code line:      ***      \n",
            "Failed line: \n",
            "Failed code line:     *****     \n",
            "Failed line: \n",
            "Failed code line:    *******    \n",
            "Failed line: \n",
            "Failed code line:   *********   \n",
            "failed tokenization qid: (19641162, 1)\n",
            "Failed line: \n",
            "Failed code line:     seen.add(ele)\n",
            "Failed line: \n",
            "Failed code line:     seen.add(ele)\n",
            "failed tokenization qid: (34569966, 3)\n",
            "Failed line: \n",
            "Failed code line:         print a\n",
            "failed tokenization qid: (31847577, 1)\n",
            "Failed line: \n",
            "Failed code line:     revbinnedstars[i] = numpy.mean(stars[np.logical_and(index1, index2)])\n",
            "failed tokenization qid: (35952815, 0)\n",
            "Failed line: \n",
            "Failed code line:     writer.writerows(reader)\n",
            "failed tokenization qid: (28416678, 1)\n",
            "Failed line: \n",
            "Failed code line: plt.show()\n",
            "failed tokenization qid: (31978879, 0)\n",
            "Failed line: \n",
            "Failed code line: main()\n",
            "failed tokenization qid: (8780912, 6)\n",
            "61000\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (36066726, 0)\n",
            "Failed line: \n",
            "Failed code line: ((?:(?!\\band\\b)[^'])*(?:'[^'\\\\]*(?:\\\\.[^'\\\\]*)*'(?:(?!\\band\\b)[^'])*)*)(?:and|$)\n",
            "failed tokenization qid: (34444319, 0)\n",
            "Failed line: \n",
            "Failed code line: np.average(a.reshape(48, -1), weights=b.ravel()), axis=1)\n",
            "failed tokenization qid: (14508570, 0)\n",
            "Failed line: \n",
            "Failed code line: conn.execute(Stopover.__table__.update().values(location_id=stmt)\n",
            "failed tokenization qid: (19241166, 2)\n",
            "Failed line: \n",
            "Failed code line:   FROM TABLE_A a\n",
            "failed tokenization qid: (3495524, 1)\n",
            "Failed line: \n",
            "Failed code line:          # If you wait longer then 5 seconds < exception\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (16257087, 1)\n",
            "Failed line: \n",
            "Failed code line: plt.imshow(np.dstack([ca_map, alpha], ...)\n",
            "failed tokenization qid: (11444222, 0)\n",
            "Failed line: \n",
            "Failed code line:  ).aggregate(worked=Sum(F('end_in_month') - F('start_in_month'))\n",
            "failed tokenization qid: (31416465, 0)\n",
            "Failed line: \n",
            "Failed code line: ['test', '172.18.74.146, 172.18.74.148', '13:05:43.834, 12:27:39.016', '2015_08_07']]\n",
            "failed tokenization qid: (32077660, 0)\n",
            "Failed line: \n",
            "Failed code line: new_list = sorted(inputList, key=lambda word: [alphabet_dict[c] for c in word[0]])\n",
            "failed tokenization qid: (10645986, 1)\n",
            "Failed line: \n",
            "Failed code line: plt.imshow(np.dstack([ca_map, ca_map, ca_map, alpha], ...)\n",
            "failed tokenization qid: (11444222, 1)\n",
            "Failed line: \n",
            "Failed code line:     # Use gtk.Builder rather than glade, you'll need to change the format of your .glade file in Glade accordingly\n",
            "failed tokenization qid: (2726839, 1)\n",
            "Failed line: \n",
            "Failed code line:             # print programinfo and query lines\n",
            "Failed line: \n",
            "Failed code line:     # skip program info always\n",
            "failed tokenization qid: (13839905, 0)\n",
            "Failed line: \n",
            "Failed code line: \n",
            "failed tokenization qid: (30443894, 0)\n",
            "Failed line: \n",
            "Failed code line:     #some operation between A[i] and A[j]\n",
            "failed tokenization qid: (36549666, 1)\n",
            "62000\n",
            "Total size: 62252. Fails: 863.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgzMEVkOieja",
        "colab_type": "text"
      },
      "source": [
        "Create vector for Tokenizer Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98nyEiH4jf16",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import ast\n",
        "code_samples = [' '.join(tokenized_code[key]) for key in tokenized_code]\n",
        "\n",
        "# convert iid_labeled keys to tuples. Then we convert to string to get question title\n",
        "question_samples = [qid_to_title[str(qid)] for qid, code_idx in [ast.literal_eval(key) for key in iid_labeled]]\n",
        "\n",
        "samples = code_samples + question_samples\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSpVa-CRgpgL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9a29c4c9-63ec-45ca-fd98-40a7b3ac994d"
      },
      "source": [
        "len(samples)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "124504"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wH1Jr4-69iYa",
        "colab_type": "text"
      },
      "source": [
        "Save samples for tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ah2gelX99smZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('data/samples_for_tokenizer.json', 'w') as write_file:\n",
        "    json.dump(samples, write_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuhTWoD9jrJG",
        "colab_type": "text"
      },
      "source": [
        "This class allows to vectorize a text corpus, by turning each text into either a sequence of integers (each integer being the index of a token in a dictionary)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsvabUz4mVJm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "\n",
        "tokenizer.fit_on_texts(samples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsc0b1kCO3tR",
        "colab_type": "text"
      },
      "source": [
        "Removing question manually labeled"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCww2v8vO72z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "b17dcab2-b1d5-4ea6-da59-a302e84a3243"
      },
      "source": [
        "print(len(iid_labeled))\n",
        "print(len(all_agreed_iid))\n",
        "\n",
        "for key, label in all_agreed_iid.items():\n",
        "  if label == 1 and key in iid_labeled:\n",
        "    iid_labeled.remove(key)\n",
        "\n",
        "print(len(iid_labeled))\n",
        "print(len(all_agreed_iid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "62252\n",
            "4884\n",
            "60083\n",
            "4884\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENHfCuVPqX8b",
        "colab_type": "text"
      },
      "source": [
        "Collecting questions and code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWzrc7u4qcD9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample = {}\n",
        "\n",
        "for key in iid_labeled:\n",
        "    qid, code_idx = ast.literal_eval(key)\n",
        "    qid = str(qid)\n",
        "\n",
        "    if qid in sample:\n",
        "      sample[qid]['code_snippets'].append(' '.join(tokenized_code[key]))\n",
        "    else:\n",
        "      sample[qid] = {}\n",
        "      sample[qid]['question'] = qid_to_title[qid]\n",
        "      sample[qid]['code_snippets'] = [' '.join(tokenized_code[key])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJ-PluBVR_ZI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "011ad220-e050-4903-c705-71a975e2a48c"
      },
      "source": [
        "sum([len(sample[qid]['code_snippets']) for qid in sample])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60083"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdBmNX7kt4SN",
        "colab_type": "text"
      },
      "source": [
        "Checking if text_to_sequences is working"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_lg9rwbu-tq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "16ecc7a9-aff0-4c5b-9e9d-0e9e20311839"
      },
      "source": [
        "text = sample['13653334']['question']\n",
        "print('Question: %s' % text)\n",
        "print(\"Vector tokenized: %s\" % tokenizer.texts_to_sequences([text])[0])\n",
        "word_index = tokenizer.word_index\n",
        "inv_word_index = {v: k for k, v in word_index.items()}\n",
        "reverse_token = [inv_word_index[k] for k in tokenizer.texts_to_sequences([text])[0]]\n",
        "print('Tokenized reversed: %s' % reverse_token)\n",
        "\n",
        "# it works for the first question as they dont have accent. \n",
        "# Tokenizer class remove accents and special characters. \n",
        "assert text.lower() == ' '.join(reverse_token)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Question: Python string formatted in double qoutes for JS\n",
            "Vector tokenized: [13, 4, 1728, 5, 696, 34223, 6, 3996]\n",
            "Tokenized reversed: ['python', 'string', 'formatted', 'in', 'double', 'qoutes', 'for', 'js']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3hwtwCvvU2_",
        "colab_type": "text"
      },
      "source": [
        "Collecting answers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAVRC3cuvXwm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "answers = []\n",
        "for key in iid_labeled:\n",
        "    answers.append(' '.join(tokenized_code[key]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_Pabp8fvZqN",
        "colab_type": "text"
      },
      "source": [
        "Tokenize answers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4woakMIvcBD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "answers_sequence = tokenizer.texts_to_sequences(answers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fq4rA2-z9QhL",
        "colab_type": "text"
      },
      "source": [
        "Save tokenized answers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsFXuDny9WP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('data/answers.json', 'w') as write_file:\n",
        "    json.dump(answers_sequence, write_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVS06sUg4XE5",
        "colab_type": "text"
      },
      "source": [
        "Questions and code tokenized to a sequence of integers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0BlX_Ps4eNf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_sequence = []\n",
        "\n",
        "for key in sample:\n",
        "  question = sample[key]['question']\n",
        "  question_sequence = tokenizer.texts_to_sequences([question])[0]\n",
        "  \n",
        "  code_snippets = sample[key]['code_snippets']\n",
        "  code_snippets_sequence = tokenizer.texts_to_sequences(code_snippets)\n",
        "  \n",
        "\n",
        "  \n",
        "  input_sequence = {'question': question_sequence, 'good_answers': code_snippets_sequence}\n",
        "  \n",
        "  sample_sequence.append(input_sequence)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Z_TERxn1kSe",
        "colab_type": "text"
      },
      "source": [
        "Creating training dataset.\n",
        "\n",
        "Its dataset contains question and good answers labeled. According to https://github.com/mrezende/StackOverflow-Question-Code-Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUK9DgVOEHbP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "4491d6d2-050b-44a5-a6a1-3b69bdded2cd"
      },
      "source": [
        "qid, code_idx = ast.literal_eval(iid_labeled[0])\n",
        "question_url = f'https://stackoverflow.com/questions/{qid}'\n",
        "print(question_url)\n",
        "print(sample_sequence[0]['question'])\n",
        "print(len(sample_sequence[0]['good_answers']))\n",
        "print(len(sample_sequence))\n",
        "print([inv_word_index[key] for key in sample_sequence[0]['question']])\n",
        "print([[inv_word_index[key] for key in code_snippet] for code_snippet in sample_sequence[0]['good_answers']])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://stackoverflow.com/questions/17335003\n",
            "[13, 979, 14, 153, 26, 727, 18, 25, 81, 45, 45, 45]\n",
            "2\n",
            "39136\n",
            "['python', 'trying', 'to', 'create', 'the', 'equivalent', 'of', 'and', 'or', 'value', 'value', 'value']\n",
            "[['var', 'set', 'string', 'string', 'newline', 'var', 'set', 'string', 'set', 'string', 'string', 'string', 'set', 'string', 'string', 'string', 'string', 'string', 'string', 'string', 'string', 'newline', 'def', 'test', 'teststring', 'newline', 'if', 'not', 'teststring', 'endswith', 'string', 'newline', 'return', 'false', 'newline', 'var', 'set', 'teststring', 'rstrip', 'string', 'lower', 'split', 'newline', 'return', 'var', 'issuperset', 'var', 'or', 'all', 'not', 'var', 'isdisjoint', 'var', 'for', 'var', 'in', 'var', 'newline', 'var', 'string', 'newline', 'var', 'string', 'newline', 'var', 'string', 'newline', 'var', 'string', 'newline', 'var', 'string', 'newline', 'print', 'var', 'newline', 'if', 'test', 'var', 'newline', 'print', 'var', 'newline', 'print', 'var', 'newline', 'if', 'test', 'var', 'newline', 'print', 'var', 'newline', 'print', 'var', 'newline', 'if', 'test', 'var', 'newline', 'print', 'var', 'newline', 'print', 'var', 'newline', 'if', 'test', 'var', 'newline', 'print', 'var', 'newline'], ['the', 'code', 'newline', 'var', 'string', 'string', 'newline', 'var', 'string', 'string', 'string', 'string', 'string', 'string', 'string', 'string', 'string', 'string', 'string', 'string', 'string', 'newline', 'def', 'test', 'teststring', 'newline', 'var', 'teststring', 'lower', 'newline', 'return', 'all', 'var', 'in', 'var', 'for', 'var', 'in', 'var', 'or', 'all', 'any', 'var', 'in', 'var', 'for', 'var', 'in', 'var', 'for', 'var', 'in', 'var', 'newline', 'var', 'string', 'newline', 'var', 'string', 'newline', 'var', 'string', 'newline', 'var', 'string', 'newline', 'print', 'var', 'newline', 'if', 'test', 'var', 'newline', 'print', 'var', 'newline', 'print', 'var', 'newline', 'if', 'test', 'var', 'newline', 'print', 'var', 'newline', 'print', 'var', 'newline', 'if', 'test', 'var', 'newline', 'print', 'var', 'newline']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0ZUi2GZF7C-",
        "colab_type": "text"
      },
      "source": [
        "Save training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ut40dvLIF-U2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('data/training.json', 'w') as write_file:\n",
        "    json.dump(sample_sequence, write_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iw4b4ZXRWg7t",
        "colab_type": "text"
      },
      "source": [
        "Collecting question and code labeled as 1 ( 'correct' )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYu1QiEiWgPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_for_evaluation = {}\n",
        "\n",
        "for key, label in all_agreed_iid.items():\n",
        "    qid, code_idx = ast.literal_eval(key)\n",
        "    qid = str(qid)\n",
        "    if label == 1:\n",
        "      if qid in sample_for_evaluation:\n",
        "        sample_for_evaluation[qid]['code_snippets'].append(' '.join(tokenized_code[key]))\n",
        "      else:\n",
        "        sample_for_evaluation[qid] = {}\n",
        "        sample_for_evaluation[qid]['question'] = qid_to_title[qid]\n",
        "        sample_for_evaluation[qid]['code_snippets'] = [' '.join(tokenized_code[key])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPCpyjPgZAZn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0dc832f1-b140-4fb2-b524-21ae1c773833"
      },
      "source": [
        "sum([len(sample_for_evaluation[qid]['code_snippets']) for qid in sample_for_evaluation])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2169"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vokXGdfpW9zF",
        "colab_type": "text"
      },
      "source": [
        "Questions and code labeled tokenized"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiyvfjcEXBrK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_for_evaluation_sequence = []\n",
        "\n",
        "for key in sample_for_evaluation:\n",
        "  question = sample_for_evaluation[key]['question']\n",
        "  question_sequence = tokenizer.texts_to_sequences([question])[0]\n",
        "  \n",
        "  code_snippets = sample_for_evaluation[key]['code_snippets']\n",
        "  code_snippets_sequence = tokenizer.texts_to_sequences(code_snippets)\n",
        "  \n",
        "  \n",
        "\n",
        "  \n",
        "  input_sequence = {'question': question_sequence, 'good_answers': code_snippets_sequence}\n",
        "  \n",
        "  sample_for_evaluation_sequence.append(input_sequence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mo_8AL2UxnO",
        "colab_type": "text"
      },
      "source": [
        "Create DEV and EVAL set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpjoLytKU0X1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "98f7bbe3-fd66-4bac-c7c9-476d0257628c"
      },
      "source": [
        "sum([len(input_sequence['good_answers']) for input_sequence in sample_for_evaluation_sequence])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2169"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rawUu8SY6Tlr",
        "colab_type": "text"
      },
      "source": [
        "Split data in DEV and EVAL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpxoIfCq6TOK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_dev, X_eval = train_test_split(\n",
        "    sample_for_evaluation_sequence, test_size=0.50, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQtvf5-mw6QA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "87045c9c-e3ef-4b1a-cdec-deae5d53f786"
      },
      "source": [
        "len(X_eval)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "721"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5ESABkV6i8Y",
        "colab_type": "text"
      },
      "source": [
        "Save DEV dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ugjx1SkS6hwj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('data/dev.json', 'w') as write_file:\n",
        "    json.dump(X_dev, write_file) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLEDoAPz6uaV",
        "colab_type": "text"
      },
      "source": [
        "Save EVAL dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zk2zae7V6wg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('data/eval.json', 'w') as write_file:\n",
        "    json.dump(X_eval, write_file) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmgcXYox32XC",
        "colab_type": "text"
      },
      "source": [
        "Compress files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Q-T4HaeGSfk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "eb05622a-6bde-4325-aabe-cbba7996c470"
      },
      "source": [
        "%cd data\n",
        "!tar -czvf samples_for_tokenizer.tar.gz samples_for_tokenizer.json\n",
        "!tar -czvf answers.tar.gz answers.json\n",
        "!tar -czvf training.tar.gz training.json \n",
        "!tar -czvf eval.tar.gz eval.json\n",
        "!tar -czvf dev.tar.gz dev.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/yacra/data\n",
            "samples_for_tokenizer.json\n",
            "answers.json\n",
            "training.json\n",
            "eval.json\n",
            "dev.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTWqE5s1DbEW",
        "colab_type": "text"
      },
      "source": [
        "compress in a single file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-kdvbZyDgtD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "43c162e6-2848-4d6d-c067-7fd72849355c"
      },
      "source": [
        "!tar -czvf data.tar.gz *.tar.gz* "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "answers.tar.gz\n",
            "dev.tar.gz\n",
            "eval.tar.gz\n",
            "samples_for_tokenizer.tar.gz\n",
            "training.tar.gz\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}